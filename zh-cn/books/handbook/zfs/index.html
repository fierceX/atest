<!DOCTYPE html>
<html class="theme-light" lang="zh-cn">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="ZFS 是一种先进的文件系统，旨在解决以前存储子系统软件中存在的主要问题。"/>
  <meta name="keywords" content="91, 34, 90, 70, 83, 34, 44, 32, 34, 102, 105, 108, 101, 115, 121, 115, 116, 101, 109, 34, 44, 32, 34, 97, 100, 109, 105, 110, 105, 115, 116, 114, 97, 116, 105, 111, 110, 34, 44, 32, 34, 122, 112, 111, 111, 108, 34, 44, 32, 34, 102, 101, 97, 116, 117, 114, 101, 115, 34, 44, 32, 34, 116, 101, 114, 109, 105, 110, 111, 108, 111, 103, 121, 34, 44, 32, 34, 82, 65, 73, 68, 45, 90, 34, 93"/>
  <meta name="copyright" content="1995-2024 The FreeBSD Foundation" />
  <link rel="canonical" href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/" />

  <title>第 22 章 Z 文件系统（ZFS） |  FreeBSD 中文文档</title>

  <meta name="theme-color" content="#790000">
  <meta name="color-scheme" content="system light dark high-contrast">

    <link rel="shortcut icon" href="https://free.bsd-doc.org/favicon.ico">
    <link rel="stylesheet" href="/styles/main.min.css">
    <link rel="stylesheet" href="https://free.bsd-doc.org/css/font-awesome-min.css">
    <script defer src="/js/theme-chooser.min.js"></script>
    <script defer src="/js/copy-clipboard.min.js"></script>
    <script defer src="/js/search.min.js"></script>

  
  
    
    <meta property="og:title" content="第 22 章 Z 文件系统（ZFS）" />
    <meta property="og:description" content="ZFS 是一种先进的文件系统，旨在解决以前存储子系统软件中存在的主要问题。" />
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://free.bsd-doc.orgfavicon.ico"/>
    <meta property="og:image:alt" content="FreeBSD Logo">
    <meta property="og:locale" content="zh-cn" />
    <meta property="og:url" content="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/" />
    <meta property="og:site_name" content="FreeBSD 中文文档" />
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Article",
        "url": "https:\/\/free.bsd-doc.org\/zh-cn\/books\/handbook\/zfs\/",
        "name": "FreeBSD 中文文档",
        "headline": "FreeBSD 中文文档",
        "description": "FreeBSD 中文文档"
      }
    </script>
    

  
</head>


  <body>
    <header>
  <div class="header-container">
    <div class="logo-menu-bars-container">
      <a href="https://free.bsd-doc.org" class="logo">
        <img src="https://free.bsd-doc.org/images/FreeBSD-monochromatic.svg" width="160" height="50" alt="FreeBSD logo" />
      </a>
      <label class="menu-bars" for="menu-bars">
        <i class="fa fa-bars" aria-hidden="true"></i>
      </label>
    </div>
    <input id="menu-bars" type="checkbox" />
    
    <div class="search-donate-container">
      
      <div class="donate">
        <a href="https://github.com/fierceX/freebsd-doc-cn" target="_blank">
          <span class="heart">♥</span>
          GitHub
        </a>
      </div>
    </div>
  </div>
</header>

    
<input type="checkbox" class="hidden toggle" id="menu-control">
<main class="main-wrapper-book">
  <a id="top"></a>
  
  <aside class="book-menu">
    <div class="book-menu-content">
      <input id="search-book" type="text" placeholder="Search" aria-label="Search" maxlength="128" />
      <nav id="MenuContents">
        
  <ul>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-8ada319c45e780947f82b569049480cc" class="toggle"  />
          <label  class="icon cursor"  for="chapter-8ada319c45e780947f82b569049480cc"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/">
              前言
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-audience">预期读者</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-changes-from4">第四版</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-changes-from3">第三版</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-changes-from2">第二版（2004 年）</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-changes">第一版（2001 年）</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-overview">本书的组织结构</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-conv">本书中使用的约定</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/preface/#preface-acknowledgements">致谢</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-32a83d18a326852a8d9ae2582360bbc8" class="toggle"  />
          <label  for="chapter-32a83d18a326852a8d9ae2582360bbc8"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/parti/">
              第一部分：入门指南
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-a4909db05d872d16d5be86a57cbc2dc7" class="toggle"  />
          <label  class="icon cursor"  for="chapter-a4909db05d872d16d5be86a57cbc2dc7"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/introduction/">
              第一章 引言
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/introduction/#introduction-synopsis">1.1. 简介</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/introduction/#nutshell">1.2. 欢迎来到 FreeBSD ！</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/introduction/#history">1.3. 关于 FreeBSD 项目</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-3c2455cadf89eadd3f6e77461085d5e9" class="toggle"  />
          <label  class="icon cursor"  for="chapter-3c2455cadf89eadd3f6e77461085d5e9"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/">
              第二章 安装 FreeBSD
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-synopsis">2.1. 简介</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-hardware">2.2. 最低硬件要求</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-pre">2.3. 安装前的任务</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-start">2.4. 开始安装</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#using-bsdinstall">2.5. 使用 bsdinstall</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-partitioning">2.6. 分配磁盘空间</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-fetching-distribution">2.7. 获取分发文件</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-post">2.8. 网络接口，账户，时区，服务和加固</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#bsdinstall-install-trouble">2.9. 故障排除</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bsdinstall/#using-live-cd">2.10. 使用 Live CD</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-709481b75d22ad36960f7ac166b3306c" class="toggle"  />
          <label  class="icon cursor"  for="chapter-709481b75d22ad36960f7ac166b3306c"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/">
              第三章. FreeBSD 基础知识
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#basics-synopsis">3.1. 概要</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#consoles">3.2. 虚拟控制台和终端</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#users-synopsis">3.3. 用户和基本账户管理</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#permissions">3.4. 权限</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#dirstructure">3.5. 目录结构</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#disk-organization">3.6. 磁盘组织</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#mount-unmount">3.7. 挂载和卸载文件系统</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#basics-processes">3.8. 进程和守护进程</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#shells">3.9. Shells</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#editors">3.10. 文本编辑器</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#basics-devices">3.11. 设备和设备节点</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/basics/#basics-more-information">3.12. 手册页</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-58c050d31a1fbecd859248dacefeb567" class="toggle"  />
          <label  class="icon cursor"  for="chapter-58c050d31a1fbecd859248dacefeb567"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/">
              第四章 安装应用程序：软件包和 Ports
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-synopsis">4.1. 简介</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-overview">4.2. 软件安装概述</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-finding-applications">4.3. 寻找软件</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#pkgng-intro">4.4. 使用 pkg 进行二进制包管理</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-using">4.5. 使用 Ports 集合</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-poudriere">4.6. 使用 poudriere 构建软件包</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-nextsteps">4.7. 安装后的考虑事项</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ports/#ports-broken">4.8. 处理损坏的 ports</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-e5a000ce7f50680a180e2c1b83c121bc" class="toggle"  />
          <label  class="icon cursor"  for="chapter-e5a000ce7f50680a180e2c1b83c121bc"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/">
              第五章 X Window 系统
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/#x11-synopsis">5.1. 简介</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/#x-install">5.2. 安装 Xorg</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/#x-graphic-card-drivers">5.3. 显卡驱动程序</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/#x-config">5.4. Xorg 配置</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/x11/#x-fonts">5.5. 在 Xorg 中使用字体</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-235af08fb87fd7a58003348706d2111d" class="toggle"  />
          <label  class="icon cursor"  for="chapter-235af08fb87fd7a58003348706d2111d"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/">
              第六章 Wayland
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-synopsis">6.1. Wayland 概述</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-wayfire">6.2. Wayfire 合成器</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-hikari">6.3. Hikari 合成器</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-sway">6.4. Sway 合成器</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-xwayland">6.5. 使用 Xwayland</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-remotedesktop">6.6. 使用 VNC 进行远程桌面访问</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-ly">6.7. Wayland 登录管理器</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wayland/#wayland-utilities">6.8. 有用的工具</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-4de18483dde20bf9ed0024176afd09da" class="toggle"  />
          <label  class="icon cursor"  for="chapter-4de18483dde20bf9ed0024176afd09da"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/">
              第 7 章 网络
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#network-synopsis">7.1. 简介</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#config-network-setup">7.2. 设置网络</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#config-network-connection">7.3. 有线网络</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#network-wireless">7.4. 无线网络</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#hostname">7.5. 主机名</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#dns">7.6. DNS</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network/#troubleshooting">7.7. 故障排除</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-5eb30759c3a2873e716dc31d7760054c" class="toggle"  />
          <label  for="chapter-5eb30759c3a2873e716dc31d7760054c"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/partii/">
              第二部分：常见任务
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-c96504f017c56f4bc7f71548cccf5382" class="toggle"  />
          <label  class="icon cursor"  for="chapter-c96504f017c56f4bc7f71548cccf5382"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/">
              Chapter 8. Desktop Environments
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-synopsis">8.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-environments">8.2. Desktop Environments</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-browsers">8.3. Browsers</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-development">8.4. Development tools</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-productivity">8.5. Desktop office productivity</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-viewers">8.6. Document Viewers</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/desktop/#desktop-finance">8.7. Finance</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-e1898af36aaacc168e13b673d25b908f" class="toggle"  />
          <label  class="icon cursor"  for="chapter-e1898af36aaacc168e13b673d25b908f"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/">
              Chapter 9. Multimedia
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#multimedia-synopsis">9.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#sound-setup">9.2. Setting Up the Sound Card</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#audio-ports">9.3. Audio players</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#video-ports">9.4. Video players</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#conferencing-meetings">9.5. Conferencing and Meetings</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/multimedia/#scanners">9.6. Image Scanners</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-6926664836e63c5cae4b2fa60855f91d" class="toggle"  />
          <label  class="icon cursor"  for="chapter-6926664836e63c5cae4b2fa60855f91d"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/">
              Chapter 10. Configuring the FreeBSD Kernel
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-synopsis">10.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-custom-kernel">10.2. Why Build a Custom Kernel?</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-devices">10.3. Finding the System Hardware</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-config">10.4. The Configuration File</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-building">10.5. Building and Installing a Custom Kernel</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/kernelconfig/#kernelconfig-trouble">10.6. If Something Goes Wrong</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-19d36bd70a320268f0ea1f66e4f3e224" class="toggle"  />
          <label  class="icon cursor"  for="chapter-19d36bd70a320268f0ea1f66e4f3e224"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/">
              Chapter 11. Printing
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-quick-start">11.1. Quick Start</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-connections">11.2. Printer Connections</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-pdls">11.3. Common Page Description Languages</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-direct">11.4. Direct Printing</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-lpd">11.5. LPD (Line Printer Daemon)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/printing/#printing-other">11.6. Other Printing Systems</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-a07f539e6c18f2db4da5dbb2b5bb1e79" class="toggle"  />
          <label  class="icon cursor"  for="chapter-a07f539e6c18f2db4da5dbb2b5bb1e79"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/linuxemu/">
              Chapter 12. Linux Binary Compatibility
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/linuxemu/#linuxemu-synopsis">12.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/linuxemu/#linuxemu-lbc-install">12.2. Configuring Linux Binary Compatibility</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/linuxemu/#linux-userlands">12.3. Linux userlands</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/linuxemu/#linuxemu-advanced">12.4. Advanced Topics</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-af234c193ce95c480af0ff5ec3f32f5c" class="toggle"  />
          <label  class="icon cursor"  for="chapter-af234c193ce95c480af0ff5ec3f32f5c"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/">
              Chapter 13. WINE
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#wine-synopsis">13.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#wine-overview-concepts">13.2. WINE Overview & Concepts</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#installing-wine-on-freebsd">13.3. Installing WINE on FreeBSD</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#running-first-wine-program">13.4. Running a First WINE Program on FreeBSD</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#configuring-wine-installation">13.5. Configuring WINE Installation</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#wine-management-guis">13.6. WINE Management GUIs</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#wine-in-multi-user-os-installations">13.7. WINE in Multi-User FreeBSD Installations</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/wine/#wine-on-os-faq">13.8. WINE on FreeBSD FAQ</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-51416fdea9d5a1dfa1c2718cd825213a" class="toggle"  />
          <label  for="chapter-51416fdea9d5a1dfa1c2718cd825213a"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/partiii/">
              第三部分：系统管理
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-532d0380ba66d66e033765a0b6930ee7" class="toggle"  />
          <label  class="icon cursor"  for="chapter-532d0380ba66d66e033765a0b6930ee7"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/">
              Chapter 14. Configuration, Services, Logging and Power Management
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#config-synopsis">14.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#configtuning-configfiles">14.2. Configuration Files</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#configtuning-rcd">14.3. Managing Services in FreeBSD</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#cron-periodic">14.4. Cron and Periodic</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#configtuning-syslog">14.5. Configuring System Logging</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#acpi-overview">14.6. Power and Resource Management</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/config/#adding-swap-space">14.7. Adding Swap Space</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-d05f41680fb7e3d68b354ae03de368b1" class="toggle"  />
          <label  class="icon cursor"  for="chapter-d05f41680fb7e3d68b354ae03de368b1"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/boot/">
              Chapter 15. The FreeBSD Booting Process
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/boot/#boot-synopsis">15.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/boot/#boot-introduction">15.2. FreeBSD Boot Process</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/boot/#device-hints">15.3. Device Hints</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/boot/#boot-shutdown">15.4. Shutdown Sequence</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-513e8e407c57354df334059688e9b60a" class="toggle"  />
          <label  class="icon cursor"  for="chapter-513e8e407c57354df334059688e9b60a"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/">
              Chapter 16. Security
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-synopsis">16.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-intro">16.2. Introduction</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#sec-accounts">16.3. Securing Accounts</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-ids">16.4. Intrusion Detection System (IDS)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-secure-levels">16.5. Secure levels</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-file-flags">16.6. File flags</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#openssh">16.7. OpenSSH</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#openssl">16.8. OpenSSL</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#kerberos5">16.9. Kerberos</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#tcpwrappers">16.10. TCP Wrappers</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#fs-acl">16.11. Access Control Lists</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#capsicum">16.12. Capsicum</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-accounting">16.13. Process Accounting</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-resourcelimits">16.14. Resource Limits</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-pkg">16.15. Monitoring Third Party Security Issues</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/security/#security-advisories">16.16. FreeBSD Security Advisories</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-0f7d2858504c83a029928c048d394e2a" class="toggle"  />
          <label  class="icon cursor"  for="chapter-0f7d2858504c83a029928c048d394e2a"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/">
              Chapter 17. Jails and Containers
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jails-synopsis">17.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jail-types">17.2. Jail Types</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#host-configuration">17.3. Host Configuration</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#classic-jail">17.4. Classic Jail (Thick Jail)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#thin-jail">17.5. Thin Jails</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jail-management">17.6. Jail Management</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jail-upgrading">17.7. Jail Upgrading</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jail-resource-limits">17.8. Jail Resource Limits</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/jails/#jail-managers-and-containers">17.9. Jail Managers and Containers</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-15be125ce5997f51c5499e3a0dee6c2c" class="toggle"  />
          <label  class="icon cursor"  for="chapter-15be125ce5997f51c5499e3a0dee6c2c"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/">
              Chapter 18. Mandatory Access Control
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-synopsis">18.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-inline-glossary">18.2. Key Terms</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-understandlabel">18.3. Understanding MAC Labels</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-planning">18.4. Planning the Security Configuration</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-policies">18.5. Available MAC Policies</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-userlocked">18.6. User Lock Down</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-implementing">18.7. Nagios in a MAC Jail</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mac/#mac-troubleshoot">18.8. Troubleshooting the MAC Framework</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-3f7e8d763b17c7d0c44c60505cf0feea" class="toggle"  />
          <label  class="icon cursor"  for="chapter-3f7e8d763b17c7d0c44c60505cf0feea"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/audit/">
              Chapter 19. Security Event Auditing
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/audit/#audit-synopsis">19.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/audit/#audit-inline-glossary">19.2. Key Terms</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/audit/#audit-config">19.3. Audit Configuration</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/audit/#audit-administration">19.4. Working with Audit Trails</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-7bb1cb2287cd08a3672cc878e604f0d0" class="toggle"  />
          <label  class="icon cursor"  for="chapter-7bb1cb2287cd08a3672cc878e604f0d0"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/">
              Chapter 20. Storage
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-synopsis">20.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-adding">20.2. Adding Disks</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-growing">20.3. Resizing and Growing Disks</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#usb-disks">20.4. USB Storage Devices</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#creating-cds">20.5. Creating and Using CD Media</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#creating-dvds">20.6. Creating and Using DVD Media</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#floppies">20.7. Creating and Using Floppy Disks</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#using-ntfs">20.8. Using NTFS Disks</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#backup-basics">20.9. Backup Basics</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-virtual">20.10. Memory Disks</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#snapshots">20.11. File System Snapshots</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#quotas">20.12. Disk Quotas</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-encrypting">20.13. Encrypting Disk Partitions</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#swap-encrypting">20.14. Encrypting Swap</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/disks/#disks-hast">20.15. Highly Available Storage (HAST)</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-dec5fc4f0100e5030db0fb188d8d4b2f" class="toggle"  />
          <label  class="icon cursor"  for="chapter-dec5fc4f0100e5030db0fb188d8d4b2f"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/">
              Chapter 21. GEOM: Modular Disk Transformation Framework
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-synopsis">21.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-striping">21.2. RAID0 - Striping</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-mirror">21.3. RAID1 - Mirroring</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-raid3">21.4. RAID3 - Byte-level Striping with Dedicated Parity</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-graid">21.5. Software RAID Devices</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-ggate">21.6. GEOM Gate Network</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-glabel">21.7. Labeling Disk Devices</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/geom/#geom-gjournal">21.8. UFS Journaling Through GEOM</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-7f1657a05627dd16bad31d4c7f675604" class="toggle"  checked  />
          <label  class="icon cursor"  for="chapter-7f1657a05627dd16bad31d4c7f675604"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/">
              第 22 章 Z 文件系统（ZFS）
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-differences">22.1. ZFS 有何不同之处</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-quickstart">22.2. 快速入门指南</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-zpool">22.3. <code>zpool</code> 管理</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-zfs">22.4. <code>zfs</code> 管理</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-zfs-allow">22.5. Delegated Administration</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-advanced">22.6. Advanced Topics</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-links">22.7. Further Resources</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/zfs/#zfs-term">22.8. ZFS Features and Terminology</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-4c6bf6828e601b79edb2813329ac6604" class="toggle"  />
          <label  class="icon cursor"  for="chapter-4c6bf6828e601b79edb2813329ac6604"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/filesystems/">
              Chapter 23. Other File Systems
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/filesystems/#filesystems-synopsis">23.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/filesystems/#filesystems-linux">23.2. Linux® File Systems</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-ae23289d4b6415f3f878893f9d3ef9b8" class="toggle"  />
          <label  class="icon cursor"  for="chapter-ae23289d4b6415f3f878893f9d3ef9b8"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/">
              Chapter 24. Virtualization
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-synopsis">24.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-guest-parallelsdesktop">24.2. FreeBSD as a Guest on Parallels Desktop for macOS®</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-guest-vmware">24.3. FreeBSD as a Guest on VMware Fusion for macOS®</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-guest-virtualbox">24.4. FreeBSD as a Guest on VirtualBox™</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-host-virtualbox">24.5. FreeBSD as a Host with VirtualBox™</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-host-bhyve">24.6. FreeBSD as a Host with bhyve</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/virtualization/#virtualization-host-xen">24.7. FreeBSD as a Xen™-Host</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-b279d2b738963a45a059268d2fae00d5" class="toggle"  />
          <label  class="icon cursor"  for="chapter-b279d2b738963a45a059268d2fae00d5"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/l10n/">
              Chapter 25. Localization - i18n/L10n Usage and Setup
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/l10n/#l10n-synopsis">25.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/l10n/#using-localization">25.2. Using Localization</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/l10n/#l10n-compiling">25.3. Finding i18n Applications</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/l10n/#lang-setup">25.4. Locale Configuration for Specific Languages</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-9e3f99bd76c861ab2e9a5f31ac421842" class="toggle"  />
          <label  class="icon cursor"  for="chapter-9e3f99bd76c861ab2e9a5f31ac421842"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/">
              Chapter 26. Updating and Upgrading FreeBSD
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#updating-upgrading-synopsis">26.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#updating-upgrading-freebsdupdate">26.2. FreeBSD Update</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#updating-bootcode">26.3. Updating Bootcode</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#updating-upgrading-documentation">26.4. Updating the Documentation Set</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#current-stable">26.5. Tracking a Development Branch</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#makeworld">26.6. Updating FreeBSD from Source</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#small-lan">26.7. Tracking for Multiple Machines</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/cutting-edge/#building-on-non-freebsd-hosts">26.8. Building on non-FreeBSD Hosts</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-3ba999091575eb04ae88235cd0fb1afa" class="toggle"  />
          <label  class="icon cursor"  for="chapter-3ba999091575eb04ae88235cd0fb1afa"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/dtrace/">
              Chapter 27. DTrace
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/dtrace/#dtrace-synopsis">27.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/dtrace/#dtrace-implementation">27.2. Implementation Differences</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/dtrace/#dtrace-enable">27.3. Enabling DTrace Support</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/dtrace/#dtrace-using">27.4. Using DTrace</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-bdb217202a0a3eef4571dd1fcd50863c" class="toggle"  />
          <label  class="icon cursor"  for="chapter-bdb217202a0a3eef4571dd1fcd50863c"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/usb-device-mode/">
              Chapter 28. USB Device Mode / USB OTG
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/usb-device-mode/#usb-device-mode-synopsis">28.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/usb-device-mode/#usb-device-mode-terminals">28.2. USB Virtual Serial Ports</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/usb-device-mode/#usb-device-mode-network">28.3. USB Device Mode Network Interfaces</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/usb-device-mode/#usb-device-mode-storage">28.4. USB Virtual Storage Device</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-6d4439926bb106ac084ecc88cfd3cfa4" class="toggle"  />
          <label  for="chapter-6d4439926bb106ac084ecc88cfd3cfa4"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/partiv/">
              第四部分：网络通信
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-05a353fcb61d8e035f7c43e14725766e" class="toggle"  />
          <label  class="icon cursor"  for="chapter-05a353fcb61d8e035f7c43e14725766e"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/">
              Chapter 29. Serial Communications
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#serial-synopsis">29.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#serial">29.2. Serial Terminology and Hardware</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#term">29.3. Terminals</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#dialup">29.4. Dial-in Service</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#dialout">29.5. Dial-out Service</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/serialcomms/#serialconsole-setup">29.6. Setting Up the Serial Console</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-7f0cbcbf6701b86eba3bbd6fc829f1b8" class="toggle"  />
          <label  class="icon cursor"  for="chapter-7f0cbcbf6701b86eba3bbd6fc829f1b8"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/">
              Chapter 30. PPP
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/#ppp-and-slip-synopsis">30.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/#userppp">30.2. Configuring PPP</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/#ppp-troubleshoot">30.3. Troubleshooting PPP Connections</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/#pppoe">30.4. Using PPP over Ethernet (PPPoE)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/ppp-and-slip/#pppoa">30.5. Using PPP over ATM (PPPoA)</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-9d023b545804f197d195dd9412749943" class="toggle"  />
          <label  class="icon cursor"  for="chapter-9d023b545804f197d195dd9412749943"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/">
              Chapter 31. Electronic Mail
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#mail-synopsis">31.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#mail-using">31.2. Mail Components</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#dragonFly-mail-agent">31.3. DragonFly Mail Agent (DMA)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#sendmail">31.4. Sendmail</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#mail-changingmta">31.5. Changing the Mail Transfer Agent</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#mail-agents">31.6. Mail User Agents</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mail/#mail-advanced">31.7. Advanced Topics</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-42b19e05d30c4135c74b9878818747a9" class="toggle"  />
          <label  class="icon cursor"  for="chapter-42b19e05d30c4135c74b9878818747a9"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/">
              Chapter 32. Network Servers
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-servers-synopsis">32.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-inetd">32.2. The inetd Super-Server</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-nfs">32.3. Network File System (NFS)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-nis">32.4. Network Information System (NIS)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-ldap">32.5. Lightweight Directory Access Protocol (LDAP)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-dhcp">32.6. Dynamic Host Configuration Protocol (DHCP)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-dns">32.7. Domain Name System (DNS)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-apache">32.8. Apache HTTP Server</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-ftp">32.9. File Transfer Protocol (FTP)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-samba">32.10. File and Print Services for Microsoft® Windows® Clients (Samba)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-ntp">32.11. Clock Synchronization with NTP</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/network-servers/#network-iscsi">32.12. iSCSI Initiator and Target Configuration</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-9554a5177d00d0e87ada408809a1fc67" class="toggle"  />
          <label  class="icon cursor"  for="chapter-9554a5177d00d0e87ada408809a1fc67"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/">
              Chapter 33. Firewalls
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-intro">33.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-concepts">33.2. Firewall Concepts</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-pf">33.3. PF</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-ipfw">33.4. IPFW</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-ipf">33.5. IPFILTER (IPF)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/firewalls/#firewalls-blacklistd">33.6. Blacklistd</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-9903a1d844ed803a436595e93ec33572" class="toggle"  />
          <label  class="icon cursor"  for="chapter-9903a1d844ed803a436595e93ec33572"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/">
              Chapter 34. Advanced Networking
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#advanced-networking-synopsis">34.1. Synopsis</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-routing">34.2. Gateways and Routes</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#configtuning-virtual-hosts">34.3. Virtual Hosts</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-advanced-wireless">34.4. Wireless Advanced Authentication</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#wireless-ad-hoc-mode">34.5. Wireless Ad-hoc Mode</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-usb-tethering">34.6. USB Tethering</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-bluetooth">34.7. Bluetooth</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-bridging">34.8. Bridging</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-aggregation">34.9. Link Aggregation and Failover</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-diskless">34.10. Diskless Operation with PXE</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#carp">34.11. Common Address Redundancy Protocol (CARP)</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/advanced-networking/#network-vlan">34.12. VLANs</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-8ca29f99c249993ee9234cb4632af7a5" class="toggle"  />
          <label  for="chapter-8ca29f99c249993ee9234cb4632af7a5"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/partv/">
              第五部分. 附录
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-0229d553ebf23ffeb945be6f32836221" class="toggle"  />
          <label  class="icon cursor"  for="chapter-0229d553ebf23ffeb945be6f32836221"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/mirrors/">
              Appendix A. Obtaining FreeBSD
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mirrors/#mirrors">A.1. Mirrors</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mirrors/#git">A.2. Using Git</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mirrors/#svn">A.3. Using Subversion</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/mirrors/#mirrors-cdrom">A.4. CD and DVD Sets</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-743c99fa278b8138914ff018e40c9231" class="toggle"  />
          <label  class="icon cursor"  for="chapter-743c99fa278b8138914ff018e40c9231"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/bibliography/">
              Appendix B. Bibliography
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bibliography/#bibliography-freebsd">B.1. FreeBSD Bibliography</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bibliography/#bibliography-security">B.2. Security Reference</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bibliography/#bibliography-history">B.3. UNIX® History</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/bibliography/#bibliography-journals">B.4. Periodicals, Journals, and Magazines</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-de7eade4b8b64f298c0cbac44c2278da" class="toggle"  />
          <label  class="icon cursor"  for="chapter-de7eade4b8b64f298c0cbac44c2278da"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/eresources/">
              Appendix C. Resources on the Internet
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/eresources/#eresources-www">C.1. Websites</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/eresources/#eresources-mail">C.2. Mailing Lists</a></li>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/eresources/#eresources-news">C.3. Usenet Newsgroups</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-bfb0d4e71c3c1a18a8b75e03f4b48e26" class="toggle"  />
          <label  class="icon cursor"  for="chapter-bfb0d4e71c3c1a18a8b75e03f4b48e26"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/pgpkeys/">
              Appendix D. OpenPGP Keys
            </a>
            
            
  <ul>
    <li><a href="https://free.bsd-doc.org/zh-cn/books/handbook/pgpkeys/#pgpkeys-officers">D.1. Officers</a></li>
  </ul>

          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-2a8deedf14429128049622ec007c9d3f" class="toggle"  />
          <label  for="chapter-2a8deedf14429128049622ec007c9d3f"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/glossary/">
              FreeBSD Glossary
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-110dbb242491bf200e51e76db171f670" class="toggle"  />
          <label  for="chapter-110dbb242491bf200e51e76db171f670"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/colophon/">
              后记
            </a>
            
            
          

        
      </li>
    
      <li>
        

          
          
          

          <input type="checkbox" id="chapter-caffbcba74982e4b26b9263ac0232bc3" class="toggle"  />
          <label  for="chapter-caffbcba74982e4b26b9263ac0232bc3"><a role="button"></a></label>

          
            
            <a href="https://free.bsd-doc.org/zh-cn/books/handbook/introduction/">
              
            </a>
            
            
          

        
      </li>
    
      <li>
        
      </li>
    
  </ul>


      </nav>
    </div>
  </aside>
  
  <div class="book">
    
    <div class="book-menu-mobile">
      <label for="menu-control">
        <span class="menu-control-button">
          <i class="fa fa-list" aria-hidden="true" title="Book menu"></i>
          Book menu
        </span>
      </label>
    </div>
    
    <h1 class="title">第 22 章 Z 文件系统（ZFS）</h1>
    
    
      <div class="admonitionblock note">
        <p>
          <i class="fa fa-exclamation-circle" aria-hidden="true"></i>
          如果发现翻译错误，请直接 <a href="https://github.com/fierceX/freebsd-doc-cn/pulls" target="_blank">发起PR修改</a>。
        </p>
      </div>
    
    
    
    <div class="toc-mobile">
      <h3>Table of Contents</h3>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#zfs-differences">22.1. ZFS 有何不同之处</a></li>
    <li><a href="#zfs-quickstart">22.2. 快速入门指南</a></li>
    <li><a href="#zfs-zpool">22.3. <code>zpool</code> 管理</a></li>
    <li><a href="#zfs-zfs">22.4. <code>zfs</code> 管理</a></li>
    <li><a href="#zfs-zfs-allow">22.5. Delegated Administration</a></li>
    <li><a href="#zfs-advanced">22.6. Advanced Topics</a></li>
    <li><a href="#zfs-links">22.7. Further Resources</a></li>
    <li><a href="#zfs-term">22.8. ZFS Features and Terminology</a></li>
  </ul>
</nav>
    </div>
    
      
      
    
    <div class="book-content">
      <div id="preamble">
<div class="sectionbody">

<div class="paragraph">
<p>ZFS 是一种先进的文件系统，旨在解决以前存储子系统软件中存在的主要问题。</p>
</div>
<div class="paragraph">
<p>最初由 Sun™ 开发，持续的开源 ZFS 开发已经转移到了 <a href="http://open-zfs.org">OpenZFS 项目</a>。</p>
</div>
<div class="paragraph">
<p>ZFS 有三个主要的设计目标：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>数据完整性：所有数据都包含数据的校验和。ZFS 会计算校验和并将其与数据一起写入。当以后读取该数据时，ZFS 会重新计算校验和。如果校验和不匹配，即检测到一个或多个数据错误，ZFS 将尝试在可用的副本、镜像或奇偶块时自动纠正错误。</p>
</li>
<li>
<p>汇集存储：将物理存储设备添加到一个池中，并从该共享池中分配存储空间。空间可供所有文件系统和卷使用，并通过在池中添加新的存储设备来增加空间。</p>
</li>
<li>
<p>性能：缓存机制提供了更高的性能。<a href="#zfs-term-arc">ARC</a> 是一种先进的基于内存的读取缓存。ZFS 提供了第二级基于磁盘的读取缓存 <a href="#zfs-term-l2arc">L2ARC</a> ，以及一种基于磁盘的同步写入缓存，名为 <a href="#zfs-term-zil">ZIL</a>。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>完整的功能和术语列表请参见 <a href="#zfs-term">ZFS Features and Terminology</a>。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-differences">22.1. ZFS 有何不同之处<a class="anchor" href="#zfs-differences"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>ZFS 不仅仅是一个文件系统，它在根本上与传统的文件系统有所不同。将卷管理器和文件系统的传统分离角色结合起来，为 ZFS 提供了独特的优势。文件系统现在能够意识到底层磁盘的结构。传统的文件系统一次只能存在于单个磁盘上。如果有两个磁盘，那么就需要创建两个单独的文件系统。传统的硬件 RAID 配置通过将操作系统呈现为由物理磁盘提供的空间组成的单个逻辑磁盘来避免这个问题，操作系统在其上放置一个文件系统。即使使用像 GEOM 提供的软件 RAID 解决方案，位于 RAID 之上的 UFS 文件系统也认为它正在处理一个单一设备。 ZFS 的卷管理器和文件系统的组合解决了这个问题，并允许创建共享可用存储池的文件系统。 ZFS 意识到物理磁盘布局的一个重要优势是，当向池中添加额外的磁盘时，现有的文件系统会自动增长。然后，这个新空间就可以供文件系统使用。 ZFS 还可以为每个文件系统应用不同的属性。这使得创建单独的文件系统和数据集比创建单个的整体文件系统更有用。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-quickstart">22.2. 快速入门指南<a class="anchor" href="#zfs-quickstart"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>FreeBSD 可以在系统初始化期间挂载 ZFS 池和数据集。要启用它，请将以下行添加到 <span class="filename">/etc/rc.conf</span>: 文件中：</p>
</div>
<div class="literalblock programlisting">
<div class="content">
<pre>zfs_enable=&#34;YES&#34;</pre>
</div>
</div>
<div class="paragraph">
<p>然后启动服务：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># service zfs start</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>本节中的示例假设有三个 SCSI 磁盘，设备名称分别为 <span class="filename">da0</span>、<span class="filename">da1</span> 和 <span class="filename">da2</span> 。使用 SATA 硬件的用户应该使用 <span class="filename">ada</span> 设备名称。</p>
</div>
<div class="sect2">
<h3 id="zfs-quickstart-single-disk-pool">22.2.1. 单磁盘池<a class="anchor" href="#zfs-quickstart-single-disk-pool"></a></h3>
<div class="paragraph">
<p>要使用单个磁盘设备创建一个简单且非冗余的池，请按以下步骤操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create example /dev/da0</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要查看新的存储池，请查看 <code>df</code> 命令的输出：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># df</span>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /example</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个输出显示了创建和挂载 <code>example</code> 池，并且现在可以作为文件系统访问。为用户创建文件以供浏览：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cd /example</span>
<span class="c"># ls</span>
<span class="c"># touch testfile</span>
<span class="c"># ls -al</span>
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 testfile</code></pre>
</div>
</div>
<div class="paragraph">
<p>此池尚未使用任何高级的 ZFS 功能和属性。要在此池上创建启用了压缩的数据集，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs create example/compressed</span>
<span class="c"># zfs set compression=gzip example/compressed</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><code>example/compressed</code> 数据集现在是一个 ZFS 压缩文件系统。尝试将一些大文件复制到 <code>/example/compressed</code>。</p>
</div>
<div class="paragraph">
<p>禁用压缩功能：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set compression=off example/compressed</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要卸载文件系统，请使用 <code>zfs umount</code> 命令，然后使用 <code>df</code> 命令进行验证：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs umount example/compressed</span>
<span class="c"># df</span>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /example</code></pre>
</div>
</div>
<div class="paragraph">
<p>要重新挂载文件系统以使其再次可访问，请使用 <code>zfs mount</code> 命令，并使用 <code>df</code> 命令进行验证：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs mount example/compressed</span>
<span class="c"># df</span>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed</code></pre>
</div>
</div>
<div class="paragraph">
<p>运行 <code>mount</code> 命令会显示池和文件系统：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># mount</span>
/dev/ad0s1a on / <span class="o">(</span>ufs, <span class="nb">local</span><span class="o">)</span>
devfs on /dev <span class="o">(</span>devfs, <span class="nb">local</span><span class="o">)</span>
/dev/ad0s1d on /usr <span class="o">(</span>ufs, <span class="nb">local</span>, soft-updates<span class="o">)</span>
example on /example <span class="o">(</span>zfs, <span class="nb">local</span><span class="o">)</span>
example/compressed on /example/compressed <span class="o">(</span>zfs, <span class="nb">local</span><span class="o">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>创建后，可以像任何文件系统一样使用 ZFS 数据集。根据需要，可以在每个数据集上设置其他可用的功能。下面的示例创建了一个名为 <code>data</code> 的新文件系统。它假设该文件系统包含重要文件，并将其配置为存储每个数据块的两个副本。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs create example/data</span>
<span class="c"># zfs set copies=2 example/data</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>使用 <code>df</code> 命令查看数据和空间使用情况：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># df</span>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /example
example/compressed  17547008       0 17547008     0%    /example/compressed
example/data        17547008       0 17547008     0%    /example/data</code></pre>
</div>
</div>
<div class="paragraph">
<p>请注意，池中的所有文件系统都具有相同的可用空间。在这些示例中使用 <code>df</code> 命令显示，文件系统使用它们所需的空间，并且都从同一个池中获取。 ZFS 摒弃了卷和分区等概念，允许多个文件系统共享同一个池。</p>
</div>
<div class="paragraph">
<p>销毁不再需要的文件系统和池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs destroy example/compressed</span>
<span class="c"># zfs destroy example/data</span>
<span class="c"># zpool destroy example</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-quickstart-raid-z">22.2.2. RAID-Z<a class="anchor" href="#zfs-quickstart-raid-z"></a></h3>
<div class="paragraph">
<p>磁盘会出现故障。避免因磁盘故障导致数据丢失的一种方法是使用 RAID。ZFS 在其存储池设计中支持此功能。 RAID-Z 存储池需要三个或更多的磁盘，但提供比镜像存储池更多的可用空间。</p>
</div>
<div class="paragraph">
<p>这个示例创建了一个 RAID-Z 池，指定要添加到池中的磁盘：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create storage raidz da0 da1 da2</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Sun™ 建议在 RAID-Z 配置中使用的设备数量应在三到九之间。对于需要由 10 个或更多磁盘组成的单个池的环境，考虑将其分成较小的 RAID-Z 组。如果有两个磁盘可用，可以使用 ZFS 镜像提供冗余性（如果需要）。有关更多详细信息，请参阅 <a href="https://man.freebsd.org/cgi/man.cgi?query=zpool&amp;sektion=8&amp;format=html">zpool(8)</a>。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>前面的示例创建了名为 <code>storage</code> 的 <code>zpool</code> 。这个示例在该池中创建了一个名为 <code>home</code> 的新文件系统：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs create storage/home</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>启用压缩并存储目录和文件的额外副本：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set copies=2 storage/home</span>
<span class="c"># zfs set compression=gzip storage/home</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要将此目录设置为用户的新家目录，请将用户数据复制到此目录并创建相应的符号链接：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp -rp /home/* /storage/home</span>
<span class="c"># rm -rf /home /usr/home</span>
<span class="c"># ln -s /storage/home /home</span>
<span class="c"># ln -s /storage/home /usr/home</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>用户数据现在存储在新创建的 <span class="filename">/storage/home</span> 上。通过添加一个新用户并以该用户身份登录来进行测试。</p>
</div>
<div class="paragraph">
<p>创建一个文件系统快照，以便以后可以回滚：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs snapshot storage/home@08-30-08</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>ZFS 创建数据集的快照，而不是单个目录或文件。</p>
</div>
<div class="paragraph">
<p><code>@</code> 字符是文件系统名称或卷名称之间的分隔符。在删除重要目录之前，先备份文件系统，然后回滚到一个早期的快照，其中目录仍然存在：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs rollback storage/home@08-30-08</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要列出所有可用的快照，请在文件系统的 <code>.zfs/snapshot</code> 目录中运行 <code>ls</code> 命令。例如，要查看已拍摄的快照：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># ls /storage/home/.zfs/snapshot</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>编写一个脚本来定期对用户数据进行快照。随着时间的推移，快照可能会占用大量的磁盘空间。使用以下命令删除先前的快照：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs destroy storage/home@08-30-08</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>经过测试，使用以下命令将 <span class="filename">/storage/home</span> 设置为真实的 <span class="filename">/home</span>：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set mountpoint=/home storage/home</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>运行 <code>df</code> 和 <code>mount</code> 命令来确认系统现在将文件系统视为真实的 <span class="filename">/home</span> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># mount</span>
/dev/ad0s1a on / <span class="o">(</span>ufs, <span class="nb">local</span><span class="o">)</span>
devfs on /dev <span class="o">(</span>devfs, <span class="nb">local</span><span class="o">)</span>
/dev/ad0s1d on /usr <span class="o">(</span>ufs, <span class="nb">local</span>, soft-updates<span class="o">)</span>
storage on /storage <span class="o">(</span>zfs, <span class="nb">local</span><span class="o">)</span>
storage/home on /home <span class="o">(</span>zfs, <span class="nb">local</span><span class="o">)</span>
<span class="c"># df</span>
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512       0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home</code></pre>
</div>
</div>
<div class="paragraph">
<p>这样就完成了 RAID-Z 的配置。通过将以下行添加到 <span class="filename">/etc/periodic.conf</span> ，可以将关于创建的文件系统的每日状态更新添加到夜间的 <a href="https://man.freebsd.org/cgi/man.cgi?query=periodic&amp;sektion=8&amp;format=html">periodic(8)</a> 运行中：</p>
</div>
<div class="literalblock programlisting">
<div class="content">
<pre>daily_status_zfs_enable=&#34;YES&#34;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-quickstart-recovering-raid-z">22.2.3. 恢复 RAID-Z<a class="anchor" href="#zfs-quickstart-recovering-raid-z"></a></h3>
<div class="paragraph">
<p>每个软件 RAID 都有一种监控其 <code>state</code> 的方法。使用以下命令查看 RAID-Z 设备的状态：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status -x</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果所有池都处于在线状态，并且一切正常，消息将显示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell">all pools are healthy</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果出现问题，比如磁盘处于 <a href="#zfs-term-offline">离线</a> 状态，池的状态将如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell">  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist <span class="k">for </span>the pool to <span class="k">continue </span>functioning <span class="k">in </span>a
	degraded state.
action: Online the device using <span class="s1">&#39;zpool online&#39;</span> or replace the device with
	<span class="s1">&#39;zpool replace&#39;</span>.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>&#34;OFFLINE&#34;显示管理员使用以下方式将 <span class="filename">da1</span> 下线：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool offline storage da1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>立即关闭计算机并更换 <span class="filename">da1</span>。重新启动计算机并将 <span class="filename">da1</span> 返回到池中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool replace storage da1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，再次检查状态，这次不使用 <code>-x</code> 选项以显示所有的池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status storage</span>
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>在这个例子中，一切都正常。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-quickstart-data-verification">22.2.4. 数据验证<a class="anchor" href="#zfs-quickstart-data-verification"></a></h3>
<div class="paragraph">
<p>ZFS 使用校验和来验证存储数据的完整性。创建文件系统时会自动启用校验和功能。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>禁用校验和是可以的，但 <strong>不推荐</strong> ！校验和占用很少的存储空间，并提供数据完整性。大多数 ZFS 功能在禁用校验和的情况下将无法正常工作。禁用这些校验和不会明显提高性能。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>验证数据校验和（称为 <em>scrubbing</em> ）可以确保 <code>storage</code> 池的完整性，具体操作如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool scrub storage</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>一个 scrub 的持续时间取决于存储的数据量。数据量越大，验证所需的时间就越长。由于 scrub 是 I/O 密集型操作， ZFS 只允许同时运行一个 scrub。在 scrub 完成后，可以使用 <code>zpool status</code> 命令查看状态。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status storage</span>
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Jan 26 19:57:37 2013
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>显示最后一次清 scrub 的完成日期有助于决定何时开始下一次 scrub。例行 scrub 有助于保护数据免受静默损坏，并确保池的完整性。</p>
</div>
<div class="paragraph">
<p>请参考 <a href="https://man.freebsd.org/cgi/man.cgi?query=zfs&amp;sektion=8&amp;format=html">zfs(8)</a> 和 <a href="https://man.freebsd.org/cgi/man.cgi?query=zpool&amp;sektion=8&amp;format=html">zpool(8)</a> 了解其他 ZFS 选项。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-zpool">22.3. <code>zpool</code> 管理<a class="anchor" href="#zfs-zpool"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>ZFS 管理使用两个主要工具。 <code>zpool</code> 工具控制池的操作，允许添加、删除、替换和管理磁盘。<code>zfs</code> 工具允许创建、销毁和管理数据集，包括文件系统和卷。</p>
</div>
<div class="sect2">
<h3 id="zfs-zpool-create">22.3.1. 创建和销毁存储池<a class="anchor" href="#zfs-zpool-create"></a></h3>
<div class="paragraph">
<p>创建一个 ZFS 存储池需要做出永久性的决策，因为在创建后无法更改池的结构。最重要的决策是将物理磁盘分组成哪种类型的 vdev 。有关可能选项的详细信息，请参阅 <a href="#zfs-term-vdev">vdev 类型 </a> 列表。创建池后，大多数 vdev 类型不允许向 vdev 添加磁盘。例外情况是镜像，它允许向 vdev 添加新磁盘，并且条带可以通过将新磁盘附加到 vdev 来升级为镜像。虽然添加新的 vdev 可以扩展池，但池的布局在创建后无法更改。取而代之的是备份数据，销毁池，然后重新创建池。</p>
</div>
<div class="paragraph">
<p>创建一个简单的镜像池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create mypool mirror /dev/ada1 /dev/ada2</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada1    ONLINE       0     0     0
            ada2    ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>要使用单个命令创建多个 vdev ，请使用以 vdev 类型关键字 <code>mirror</code> 分隔的磁盘组。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create mypool mirror /dev/ada1 /dev/ada2 mirror /dev/ada3 /dev/ada4</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada1    ONLINE       0     0     0
            ada2    ONLINE       0     0     0
          mirror-1  ONLINE       0     0     0
            ada3    ONLINE       0     0     0
            ada4    ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>池还可以使用分区而不是整个磁盘。将 ZFS 放在单独的分区中可以使同一磁盘具有其他用途的分区。特别是，它允许添加带有引导代码和用于引导的文件系统的分区。这样就可以从同时也是池成员的磁盘启动。在 FreeBSD 上，使用分区而不是整个磁盘时， ZFS 不会带来性能损失。使用分区还允许管理员对磁盘进行“欠配置”，使用不到全部容量。如果将来替换的磁盘与原始磁盘的名义大小相同，但实际容量略小，较小的分区仍将适应替换磁盘。</p>
</div>
<div class="paragraph">
<p>使用分区创建一个 <a href="#zfs-term-vdev-raidz">RAID-Z2</a> 池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create mypool raidz2 /dev/ada0p3 /dev/ada1p3 /dev/ada2p3 /dev/ada3p3 /dev/ada4p3 /dev/ada5p3</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          raidz2-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0
            ada3p3  ONLINE       0     0     0
            ada4p3  ONLINE       0     0     0
            ada5p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>销毁一个不再需要的池以重用磁盘。销毁池需要先卸载该池中的文件系统。如果有任何数据集正在使用中，卸载操作将失败，不会销毁池。可以使用 <code>-f</code> 强制销毁池。这可能会导致应用程序中对这些数据集有打开文件的未定义行为。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-attach">22.3.2. 添加和移除设备<a class="anchor" href="#zfs-zpool-attach"></a></h3>
<div class="paragraph">
<p>有两种方法可以将磁盘添加到池中：使用 <code>zpool attach</code> 将磁盘附加到现有的 vdev 上，或者使用 <code>zpool add</code> 将 vdev 添加到池中。一些 <a href="#zfs-term-vdev">vdev 类型 </a> 允许在创建后向 vdev 添加磁盘。</p>
</div>
<div class="paragraph">
<p>使用单个磁盘创建的池缺乏冗余性。它可以检测到损坏，但无法修复，因为没有其他数据的副本。 <a href="#zfs-term-copies">copies</a> 属性可以从小故障（如坏扇区）中恢复，但不提供与镜像或 RAID-Z 相同级别的保护。从由单个磁盘 vdev 组成的池开始，使用 <code>zpool attach</code> 将新磁盘添加到 vdev 中，创建镜像。还可以使用 <code>zpool attach</code> 将新磁盘添加到镜像组，增加冗余性和读取性能。在为池分区的磁盘上，将第一个磁盘的布局复制到第二个磁盘上。使用 <code>gpart backup</code> 和 <code>gpart restore</code> 可以使这个过程更容易。</p>
</div>
<div class="paragraph">
<p>通过连接 <span class="filename">ada0p3</span>，将单个磁盘（条带）vdev <span class="filename">ada1p3</span> 升级为镜像：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          ada0p3    ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool attach mypool ada0p3 ada1p3</span>
Make sure to <span class="nb">wait </span><span class="k">until </span>resilvering finishes before rebooting.

If you boot from pool <span class="s1">&#39;mypool&#39;</span>, you may need to update boot code on newly attached disk _ada1p3_.

Assuming you use GPT partitioning and _da0_ is your new boot disk you may use the following <span class="nb">command</span>:

        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0
<span class="c"># gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1</span>
bootcode written to ada1
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
status: One or more devices is currently being resilvered.  The pool will
        <span class="k">continue </span>to <span class="k">function</span>, possibly <span class="k">in </span>a degraded state.
action: Wait <span class="k">for </span>the resilver to complete.
  scan: resilver <span class="k">in </span>progress since Fri May 30 08:19:19 2014
        527M scanned out of 781M at 47.9M/s, 0h0m to go
        527M resilvered, 67.53% <span class="k">done
</span>config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0  <span class="o">(</span>resilvering<span class="o">)</span>

errors: No known data errors
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: resilvered 781M <span class="k">in </span>0h0m with 0 errors on Fri May 30 08:15:58 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>当无法将磁盘添加到现有的 vdev 时，例如对于 RAID-Z ，一种替代方法是向池中添加另一个 vdev 。添加 vdev 可以通过在 vdev 之间分布写操作来提供更高的性能。每个 vdev 都提供自己的冗余性。可以混合使用 <code>mirror</code> 和 <code>RAID-Z</code> 等不同类型的 vdev ，但不建议这样做。向包含镜像或 RAID-Z vdev 的池中添加一个非冗余的 vdev 会对整个池中的数据造成风险。分布写操作意味着非冗余磁盘的故障将导致丢失对池中每个块的一部分数据。</p>
</div>
<div class="paragraph">
<p>ZFS 将数据跨越每个 vdev 进行条带化。例如，使用两个镜像 vdev ，这实际上是一个 RAID 10，将写操作跨越两组镜像。ZFS 分配空间以使每个 vdev 在同一时间达到 100 ％的使用率。如果 vdev 具有不同数量的可用空间，性能将降低，因为更多的数据写入将发送到使用率较低的 vdev。</p>
</div>
<div class="paragraph">
<p>在将新设备连接到引导池时，请记得更新引导代码。</p>
</div>
<div class="paragraph">
<p>将第二个镜像组（<span class="filename">ada2p3</span> 和 <span class="filename">ada3p3</span>）附加到现有的镜像中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: resilvered 781M <span class="k">in </span>0h0m with 0 errors on Fri May 30 08:19:35 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool add mypool mirror ada2p3 ada3p3</span>
<span class="c"># gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2</span>
bootcode written to ada2
<span class="c"># gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada3</span>
bootcode written to ada3
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: scrub repaired 0 <span class="k">in </span>0h0m with 0 errors on Fri May 30 08:29:51 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0
          mirror-1  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0
            ada3p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>从池中删除 vdev 是不可能的，如果剩余的冗余足够，从镜像中删除磁盘是独占的。如果镜像组中只剩下一个磁盘，该组将不再是镜像，而变成条带，如果该剩余磁盘故障，将会危及整个池。</p>
</div>
<div class="paragraph">
<p>从三路镜像组中移除一个磁盘：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: scrub repaired 0 <span class="k">in </span>0h0m with 0 errors on Fri May 30 08:29:51 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool detach mypool ada2p3</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: scrub repaired 0 <span class="k">in </span>0h0m with 0 errors on Fri May 30 08:29:51 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-status">22.3.3. 检查池的状态<a class="anchor" href="#zfs-zpool-status"></a></h3>
<div class="paragraph">
<p>池状态非常重要。如果驱动器离线或 ZFS 检测到读取、写入或校验错误，相应的错误计数会增加。<code>status</code> 输出显示了池中每个设备的配置和状态，以及整个池的状态。还显示了要采取的操作和有关上次 <code>scrub</code> 的详细信息。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: scrub repaired 0 <span class="k">in </span>2h25m with 0 errors on Sat Sep 14 04:25:50 2013
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          raidz2-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0
            ada3p3  ONLINE       0     0     0
            ada4p3  ONLINE       0     0     0
            ada5p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-clear">22.3.4. 清除错误<a class="anchor" href="#zfs-zpool-clear"></a></h3>
<div class="paragraph">
<p>当检测到错误时，ZFS 会增加读取、写入或校验和错误计数。使用 <code>zpool clear <em>mypool</em></code> 命令清除错误消息并重置计数。清除错误状态对于自动化脚本非常重要，这些脚本在池遇到错误时会通知管理员。如果不清除旧错误，这些脚本可能无法报告后续的错误。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-replace">22.3.5. 替换一个正常工作的设备<a class="anchor" href="#zfs-zpool-replace"></a></h3>
<div class="paragraph">
<p>可能需要用不同的磁盘替换一个磁盘。当替换一个工作中的磁盘时，该过程会在替换期间保持旧磁盘在线。池永远不会进入 <a href="#zfs-term-degraded">降级</a> 状态，从而降低数据丢失的风险。运行 <code>zpool replace</code> 命令将数据从旧磁盘复制到新磁盘。操作完成后， ZFS 会将旧磁盘与 vdev 断开连接。如果新磁盘比旧磁盘大，可能可以使用新空间来扩展 zpool 。请参见 <a href="#zfs-zpool-online ">扩展池</a> 。</p>
</div>
<div class="paragraph">
<p>替换池中的一个正常工作设备：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool replace mypool ada1p3 ada2p3</span>
Make sure to <span class="nb">wait </span><span class="k">until </span>resilvering finishes before rebooting.

When booting from the pool <span class="s1">&#39;zroot&#39;</span>, update the boot code on the newly attached disk <span class="s1">&#39;ada2p3&#39;</span>.

Assuming GPT partitioning is used and <span class="o">[</span>.filename]#da0# is the new boot disk, use the following <span class="nb">command</span>:

        gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 da0
<span class="c"># gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada2</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
status: One or more devices is currently being resilvered.  The pool will
        <span class="k">continue </span>to <span class="k">function</span>, possibly <span class="k">in </span>a degraded state.
action: Wait <span class="k">for </span>the resilver to complete.
  scan: resilver <span class="k">in </span>progress since Mon Jun  2 14:21:35 2014
        604M scanned out of 781M at 46.5M/s, 0h0m to go
        604M resilvered, 77.39% <span class="k">done
</span>config:

        NAME             STATE     READ WRITE CKSUM
        mypool           ONLINE       0     0     0
          mirror-0       ONLINE       0     0     0
            ada0p3       ONLINE       0     0     0
            replacing-1  ONLINE       0     0     0
              ada1p3     ONLINE       0     0     0
              ada2p3     ONLINE       0     0     0  <span class="o">(</span>resilvering<span class="o">)</span>

errors: No known data errors
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: resilvered 781M <span class="k">in </span>0h0m with 0 errors on Mon Jun  2 14:21:52 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-resilver">22.3.6. 处理故障设备<a class="anchor" href="#zfs-zpool-resilver"></a></h3>
<div class="paragraph">
<p>当池中的磁盘发生故障时，该磁盘所属的 vdev 将进入 <a href="#zfs-term-degraded">降级</a> 状态。数据仍然可用，但性能降低，因为 ZFS 会通过可用的冗余计算缺失的数据。为了将 vdev 恢复到完全功能状态，需要替换故障的物理设备。然后，ZFS 会开始 <a href="#zfs-term-resilver">同步</a> 操作。ZFS 会通过可用的冗余重新计算故障设备上的数据，并将其写入替代设备。完成后，vdev 将返回 <a href="#zfs-term-online">在线</a> 状态。</p>
</div>
<div class="paragraph">
<p>如果 vdev 没有任何冗余，或者设备已经损坏且没有足够的冗余来弥补，那么存储池将进入 <a href="#zfs-term-faulted">故障</a> 状态。除非有足够的设备重新连接存储池，否则存储池将无法运行，需要从备份中恢复数据。</p>
</div>
<div class="paragraph">
<p>当替换一个故障磁盘时，故障磁盘的名称会变为新磁盘的 GUID。如果替换设备具有相同的设备名称，则不需要为 <code>zpool replace</code> 指定新的设备名称参数。</p>
</div>
<div class="paragraph">
<p>使用 <code>zpool replace</code> 命令替换故障的磁盘：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: DEGRADED
status: One or more devices could not be opened.  Sufficient replicas exist <span class="k">for
        </span>the pool to <span class="k">continue </span>functioning <span class="k">in </span>a degraded state.
action: Attach the missing device and online it using <span class="s1">&#39;zpool online&#39;</span>.
   see: http://illumos.org/msg/ZFS-8000-2Q
  scan: none requested
config:

        NAME                    STATE     READ WRITE CKSUM
        mypool                  DEGRADED     0     0     0
          mirror-0              DEGRADED     0     0     0
            ada0p3              ONLINE       0     0     0
            316502962686821739  UNAVAIL      0     0     0  was /dev/ada1p3

errors: No known data errors
<span class="c"># zpool replace mypool 316502962686821739 ada2p3</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: DEGRADED
status: One or more devices is currently being resilvered.  The pool will
        <span class="k">continue </span>to <span class="k">function</span>, possibly <span class="k">in </span>a degraded state.
action: Wait <span class="k">for </span>the resilver to complete.
  scan: resilver <span class="k">in </span>progress since Mon Jun  2 14:52:21 2014
        641M scanned out of 781M at 49.3M/s, 0h0m to go
        640M resilvered, 82.04% <span class="k">done
</span>config:

        NAME                        STATE     READ WRITE CKSUM
        mypool                      DEGRADED     0     0     0
          mirror-0                  DEGRADED     0     0     0
            ada0p3                  ONLINE       0     0     0
            replacing-1             UNAVAIL      0     0     0
              15732067398082357289  UNAVAIL      0     0     0  was /dev/ada1p3/old
              ada2p3                ONLINE       0     0     0  <span class="o">(</span>resilvering<span class="o">)</span>

errors: No known data errors
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: resilvered 781M <span class="k">in </span>0h0m with 0 errors on Mon Jun  2 14:52:38 2014
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-scrub">22.3.7. Scrubbing 池<a class="anchor" href="#zfs-zpool-scrub"></a></h3>
<div class="paragraph">
<p>定期对池进行 <a href="#zfs-term-scrub">scrub</a> 操作，最好每个月至少一次。<code>scrub</code> 操作对磁盘的使用较高，运行时会降低性能。在安排 <code>scrub</code> 操作时避免高负载时段，或者使用 <a href="#zfs-advanced-tuning-scrub_delay"><code>vfs.zfs.scrub_delay</code></a> 来调整 <code>scrub</code> 操作的相对优先级，以防止其影响其他工作负载的速度。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool scrub mypool</span>
<span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
  scan: scrub <span class="k">in </span>progress since Wed Feb 19 20:52:54 2014
        116G scanned out of 8.60T at 649M/s, 3h48m to go
        0 repaired, 1.32% <span class="k">done
</span>config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          raidz2-0  ONLINE       0     0     0
            ada0p3  ONLINE       0     0     0
            ada1p3  ONLINE       0     0     0
            ada2p3  ONLINE       0     0     0
            ada3p3  ONLINE       0     0     0
            ada4p3  ONLINE       0     0     0
            ada5p3  ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果需要取消一个 scrub 操作，请运行 <code>zpool scrub -s <em>mypool</em></code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-selfheal">22.3.8. 自我修复<a class="anchor" href="#zfs-zpool-selfheal"></a></h3>
<div class="paragraph">
<p>存储在数据块中的校验和使文件系统能够自我修复。这个功能会自动修复数据，如果其校验和与存储池中另一个设备上记录的校验和不匹配。例如，一个具有两个磁盘的镜像配置，其中一个驱动器开始出现故障，无法正确存储数据。当数据长时间未被访问时，如长期存档存储，情况会更糟。传统的文件系统需要运行检查和修复数据的命令，如 <a href="https://man.freebsd.org/cgi/man.cgi?query=fsck&amp;sektion=8&amp;format=html">fsck(8)</a>。这些命令需要时间，在严重情况下，管理员必须决定执行哪个修复操作。当 ZFS 检测到一个数据块的校验和不匹配时，它会尝试从镜像磁盘中读取数据。如果该磁盘能提供正确的数据， ZFS 将将其提供给应用程序，并纠正具有错误校验和的磁盘上的数据。在正常存储池操作期间，这一切都在没有任何系统管理员干预的情况下发生。</p>
</div>
<div class="paragraph">
<p>下一个示例通过创建一个镜像磁盘池来展示这种自我修复行为，其中包括 <span class="filename">/dev/ada0</span> 和 <span class="filename">/dev/ada1</span>。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool create healer mirror /dev/ada0 /dev/ada1</span>
<span class="c"># zpool status healer</span>
  pool: healer
 state: ONLINE
  scan: none requested
config:

    NAME        STATE     READ WRITE CKSUM
    healer      ONLINE       0     0     0
      mirror-0  ONLINE       0     0     0
       ada0     ONLINE       0     0     0
       ada1     ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool list</span>
NAME     SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT
healer   960M  92.5K   960M         -         -     0%    0%  1.00x  ONLINE  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>将一些重要数据复制到池中，以使用自我修复功能保护免受数据错误，并为池创建校验和以备后续比较。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp /some/important/data /healer</span>
<span class="c"># zfs list</span>
NAME     SIZE  ALLOC   FREE    CAP  DEDUP  HEALTH  ALTROOT
healer   960M  67.7M   892M     7%  1.00x  ONLINE  -
<span class="c"># sha1 /healer &gt; checksum.txt</span>
<span class="c"># cat checksum.txt</span>
SHA1 <span class="o">(</span>/healer<span class="o">)</span> <span class="o">=</span> 2753eff56d77d9a536ece6694bf0a82740344d1f</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过向镜像中的一个磁盘的开头写入随机数据来模拟数据损坏。为了防止 ZFS 在检测到数据损坏时修复数据，可以在损坏之前导出池，并在之后重新导入。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>这是一个危险的操作，可能会破坏重要数据，仅用于演示目的。在存储池的正常运行期间，请 <strong>不要尝试</strong> 执行此操作。此意外损坏示例也不应在任何使用 ZFS 以外的文件系统的磁盘上运行，该磁盘上的另一个分区中也不应该有 ZFS 。请不要使用除了存储池中的设备名称之外的任何其他磁盘设备名称。确保存储池有适当的备份，并在执行命令之前对其进行测试！</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool export healer</span>
<span class="c"># dd if=/dev/random of=/dev/ada1 bs=1m count=200</span>
200+0 records <span class="k">in
</span>200+0 records out
209715200 bytes transferred <span class="k">in </span>62.992162 secs <span class="o">(</span>3329227 bytes/sec<span class="o">)</span>
<span class="c"># zpool import healer</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>池状态显示一个设备发生了错误。请注意，从池中读取数据的应用程序没有接收到任何错误数据。ZFS 从 <span class="filename">ada0</span> 设备提供了正确校验和的数据。要找到校验和错误的设备，请查找 <code>CKSUM</code> 列中包含非零值的设备。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status healer</span>
    pool: healer
   state: ONLINE
  status: One or more devices has experienced an unrecoverable error.  An
          attempt was made to correct the error.  Applications are unaffected.
  action: Determine <span class="k">if </span>the device needs to be replaced, and clear the errors
          using <span class="s1">&#39;zpool clear&#39;</span> or replace the device with <span class="s1">&#39;zpool replace&#39;</span>.
     see: http://illumos.org/msg/ZFS-8000-4J
    scan: none requested
  config:

      NAME        STATE     READ WRITE CKSUM
      healer      ONLINE       0     0     0
        mirror-0  ONLINE       0     0     0
         ada0     ONLINE       0     0     0
         ada1     ONLINE       0     0     1

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>ZFS 检测到错误，并通过使用未受影响的 <span class="filename">ada0</span> 镜像磁盘中的冗余来处理该错误。通过与原始数据进行校验比较，可以确定池是否恢复一致。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># sha1 /healer &gt;&gt; checksum.txt</span>
<span class="c"># cat checksum.txt</span>
SHA1 <span class="o">(</span>/healer<span class="o">)</span> <span class="o">=</span> 2753eff56d77d9a536ece6694bf0a82740344d1f
SHA1 <span class="o">(</span>/healer<span class="o">)</span> <span class="o">=</span> 2753eff56d77d9a536ece6694bf0a82740344d1f</code></pre>
</div>
</div>
<div class="paragraph">
<p>在故意篡改之前和之后生成校验和，同时池数据仍然匹配。这显示了当校验和不同时， ZFS 能够自动检测和纠正任何错误。请注意，这需要池中具有足够的冗余。由单个设备组成的池没有自我修复能力。这也是为什么在 ZFS 中校验和如此重要的原因；不要出于任何原因禁用它们。 ZFS 不需要 <a href="https://man.freebsd.org/cgi/man.cgi?query=fsck&amp;sektion=8&amp;format=html">fsck(8)</a> 或类似的文件系统一致性检查程序来检测和纠正这个问题，并且在出现问题时保持池可用。现在需要进行一次 scrub 操作来覆盖在 <span class="filename">ada1</span> 上的损坏数据。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool scrub healer</span>
<span class="c"># zpool status healer</span>
  pool: healer
 state: ONLINE
status: One or more devices has experienced an unrecoverable error.  An
            attempt was made to correct the error.  Applications are unaffected.
action: Determine <span class="k">if </span>the device needs to be replaced, and clear the errors
            using <span class="s1">&#39;zpool clear&#39;</span> or replace the device with <span class="s1">&#39;zpool replace&#39;</span>.
   see: http://illumos.org/msg/ZFS-8000-4J
  scan: scrub <span class="k">in </span>progress since Mon Dec 10 12:23:30 2012
        10.4M scanned out of 67.0M at 267K/s, 0h3m to go
        9.63M repaired, 15.56% <span class="k">done
</span>config:

    NAME        STATE     READ WRITE CKSUM
    healer      ONLINE       0     0     0
      mirror-0  ONLINE       0     0     0
       ada0     ONLINE       0     0     0
       ada1     ONLINE       0     0   627  <span class="o">(</span>repairing<span class="o">)</span>

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>Scrub 操作从 <span class="filename">ada0</span> 读取数据，并将任何具有错误校验和的数据重写到 <span class="filename">ada1</span> 上，这可以通过 <code>zpool status</code> 中的 <code>(repairing)</code> 输出来显示。操作完成后，池的状态将发生变化：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status healer</span>
  pool: healer
 state: ONLINE
status: One or more devices has experienced an unrecoverable error.  An
        attempt was made to correct the error.  Applications are unaffected.
action: Determine <span class="k">if </span>the device needs to be replaced, and clear the errors
             using <span class="s1">&#39;zpool clear&#39;</span> or replace the device with <span class="s1">&#39;zpool replace&#39;</span>.
   see: http://illumos.org/msg/ZFS-8000-4J
  scan: scrub repaired 66.5M <span class="k">in </span>0h2m with 0 errors on Mon Dec 10 12:26:25 2012
config:

    NAME        STATE     READ WRITE CKSUM
    healer      ONLINE       0     0     0
      mirror-0  ONLINE       0     0     0
       ada0     ONLINE       0     0     0
       ada1     ONLINE       0     0 2.72K

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>在从 <span class="filename">ada0</span> 同步所有数据到 <span class="filename">ada1</span> 后，完成了 <a href="#zfs-zpool-clear">清洗</a> 操作，请通过运行 <code>zpool clear</code> 命令清除池状态中的错误消息。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool clear healer</span>
<span class="c"># zpool status healer</span>
  pool: healer
 state: ONLINE
  scan: scrub repaired 66.5M <span class="k">in </span>0h2m with 0 errors on Mon Dec 10 12:26:25 2012
config:

    NAME        STATE     READ WRITE CKSUM
    healer      ONLINE       0     0     0
      mirror-0  ONLINE       0     0     0
       ada0     ONLINE       0     0     0
       ada1     ONLINE       0     0     0

errors: No known data errors</code></pre>
</div>
</div>
<div class="paragraph">
<p>现在，池已经恢复到完全正常的状态，所有错误计数都为零。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-online">22.3.9. 扩展池<a class="anchor" href="#zfs-zpool-online"></a></h3>
<div class="paragraph">
<p>每个 vdev 中最小的设备限制了冗余池的可用大小。用一个更大的设备替换最小的设备。在完成 <a href="#zfs-zpool-replace ">replace</a> 或 <a href="#zfs-term-resilver ">resilver</a> 操作后，池可以扩展到使用新设备的容量。例如，考虑一个由 1 TB 驱动器和 2 TB 驱动器组成的镜像。可用空间为 1 TB 。当用另一个 2 TB 驱动器替换 1 TB 驱动器时，重新同步过程将现有数据复制到新驱动器上。由于两个设备现在都具有 2 TB 的容量，镜像的可用空间增长到 2 TB。</p>
</div>
<div class="paragraph">
<p>通过在每个设备上使用 <code>zpool online -e</code> 来开始扩展。在扩展所有设备之后，额外的空间将可用于池。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-import">22.3.10. 导入和导出存储池<a class="anchor" href="#zfs-zpool-import"></a></h3>
<div class="paragraph">
<p>在将存储池移动到另一个系统之前，请先 <em>导出（export）</em> 它们。 ZFS 会卸载所有数据集，并将每个设备标记为已导出，但仍然锁定以防止其他磁盘使用。这使得存储池可以在其他支持 ZFS 的机器、其他操作系统甚至不同的硬件架构上导入（有一些注意事项，请参阅 <a href="https://man.freebsd.org/cgi/man.cgi?query=zpool&amp;sektion=8&amp;format=html">zpool(8)</a>）。当数据集有打开的文件时，请使用 <code>zpool export -f</code> 强制导出存储池。请谨慎使用此功能。数据集将被强制卸载，可能导致那些数据集上有打开文件的应用程序出现意外行为。</p>
</div>
<div class="paragraph">
<p>导出一个未使用的池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool export mypool</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>导入一个存储池会自动挂载数据集。如果不希望出现这种行为，请使用 <code>zpool import -N</code> 来阻止它。 <code>zpool import -o</code> 为此特定导入设置临时属性。<code>zpool import altroot=</code> 允许使用基本挂载点而不是文件系统的根来导入存储池。如果该存储池最后在另一个系统上使用并且没有正确导出，请使用 <code>zpool import -f</code> 来强制导入。<code>zpool import -a</code> 导入所有未被其他系统使用的存储池。</p>
</div>
<div class="paragraph">
<p>列出所有可导入的池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool import</span>
   pool: mypool
     id: 9930174748043525076
  state: ONLINE
 action: The pool can be imported using its name or numeric identifier.
 config:

        mypool      ONLINE
          ada2p3    ONLINE</code></pre>
</div>
</div>
<div class="paragraph">
<p>导入具有替代根目录的池：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool import -o altroot=/mnt mypool</span>
<span class="c"># zfs list</span>
zfs list
NAME                 USED  AVAIL  REFER  MOUNTPOINT
mypool               110K  47.0G    31K  /mnt/mypool</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-upgrade">22.3.11. 升级存储池<a class="anchor" href="#zfs-zpool-upgrade"></a></h3>
<div class="paragraph">
<p>在升级 FreeBSD 之后，或者从使用较旧版本的系统导入池时，需要手动将池升级到最新的 ZFS 版本以支持新功能。在升级之前，请考虑池是否可能需要在较旧的系统上导入。升级是一个单向过程。升级较旧的池是可能的，但是无法降级具有较新功能的池。</p>
</div>
<div class="paragraph">
<p>将 v28 池升级以支持 <code>Feature Flags</code>。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
status: The pool is formatted using a legacy on-disk format.  The pool can
        still be used, but some features are unavailable.
action: Upgrade the pool using <span class="s1">&#39;zpool upgrade&#39;</span>.  Once this is <span class="k">done</span>, the
        pool will no longer be accessible on software that does not support feat
        flags.
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
	    ada0    ONLINE       0     0     0
	    ada1    ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool upgrade</span>
This system supports ZFS pool feature flags.

The following pools are formatted with legacy version numbers and are upgraded to use feature flags.
After being upgraded, these pools will no longer be accessible by software that does not support feature flags.

VER  POOL
---  ------------
28   mypool

Use <span class="s1">&#39;zpool upgrade -v&#39;</span> <span class="k">for </span>a list of available legacy versions.
Every feature flags pool has all supported features enabled.
<span class="c"># zpool upgrade mypool</span>
This system supports ZFS pool feature flags.

Successfully upgraded <span class="s1">&#39;mypool&#39;</span> from version 28 to feature flags.
Enabled the following features on <span class="s1">&#39;mypool&#39;</span>:
  async_destroy
  empty_bpobj
  lz4_compress
  multi_vdev_crash_dump</code></pre>
</div>
</div>
<div class="paragraph">
<p>只有在完成 <code>zpool upgrade</code> 之后，ZFS 的新功能才会可用。使用 <code>zpool upgrade -v</code> 命令查看升级提供的新功能，以及已经支持的功能。</p>
</div>
<div class="paragraph">
<p>升级一个池子以支持新的功能标志：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool status</span>
  pool: mypool
 state: ONLINE
status: Some supported features are not enabled on the pool. The pool can
        still be used, but some features are unavailable.
action: Enable all features using <span class="s1">&#39;zpool upgrade&#39;</span>. Once this is <span class="k">done</span>,
        the pool may no longer be accessible by software that does not support
        the features. See zpool-features<span class="o">(</span>7<span class="o">)</span> <span class="k">for </span>details.
  scan: none requested
config:

        NAME        STATE     READ WRITE CKSUM
        mypool      ONLINE       0     0     0
          mirror-0  ONLINE       0     0     0
	    ada0    ONLINE       0     0     0
	    ada1    ONLINE       0     0     0

errors: No known data errors
<span class="c"># zpool upgrade</span>
This system supports ZFS pool feature flags.

All pools are formatted using feature flags.

Some supported features are not enabled on the following pools. Once a
feature is enabled the pool may become incompatible with software
that does not support the feature. See zpool-features<span class="o">(</span>7<span class="o">)</span> <span class="k">for </span>details.

POOL  FEATURE
---------------
zstore
      multi_vdev_crash_dump
      spacemap_histogram
      enabled_txg
      hole_birth
      extensible_dataset
      bookmarks
      filesystem_limits
<span class="c"># zpool upgrade mypool</span>
This system supports ZFS pool feature flags.

Enabled the following features on <span class="s1">&#39;mypool&#39;</span>:
  spacemap_histogram
  enabled_txg
  hole_birth
  extensible_dataset
  bookmarks
  filesystem_limits</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>更新从池中引导的系统的引导代码，以支持新的池版本。在包含引导代码的分区上使用 <code>gpart bootcode</code> 命令。根据系统的引导方式，有两种类型的引导代码可用：GPT（最常见的选项）和 EFI（适用于更现代的系统）。</p>
</div>
<div class="paragraph">
<p>对于使用 GPT 的传统引导，请使用以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># gpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>对于使用 EFI 引导的系统，请执行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># gpart bootcode -p /boot/boot1.efifat -i 1 ada1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>将引导代码应用于池中的所有可引导磁盘。有关更多信息，请参阅 <a href="https://man.freebsd.org/cgi/man.cgi?query=gpart&amp;sektion=8&amp;format=html">gpart(8)</a>。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-history">22.3.12. 显示池的历史记录<a class="anchor" href="#zfs-zpool-history"></a></h3>
<div class="paragraph">
<p>ZFS 记录更改池的命令，包括创建数据集、更改属性或替换磁盘。查看关于池创建的历史记录很有用，还可以检查哪个用户执行了特定的操作以及何时执行的。历史记录不会保存在日志文件中，而是作为池本身的一部分。用于查看这个历史记录的命令被恰当地命名为 <code>zpool history</code>。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool history</span>
History <span class="k">for</span> <span class="s1">&#39;tank&#39;</span>:
2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1
2013-02-27.18:50:58 zfs <span class="nb">set </span><span class="nv">atime</span><span class="o">=</span>off tank
2013-02-27.18:51:09 zfs <span class="nb">set </span><span class="nv">checksum</span><span class="o">=</span>fletcher4 tank
2013-02-27.18:51:18 zfs create tank/backup</code></pre>
</div>
</div>
<div class="paragraph">
<p>输出显示了 <code>zpool</code> 和 <code>zfs</code> 命令以某种方式修改了池，并附带了时间戳。不包括像 <code>zfs list</code> 这样的命令。当未指定池名称时， ZFS 会显示所有池的历史记录。</p>
</div>
<div class="paragraph">
<p>当使用选项 <code>-i</code> 或 <code>-l</code> 时，<code>zpool history</code> 命令可以显示更多的信息。 <code>-i</code> 选项会显示用户发起的事件以及内部记录的 ZFS 事件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool history -i</span>
History <span class="k">for</span> <span class="s1">&#39;tank&#39;</span>:
2013-02-26.23:02:35 <span class="o">[</span>internal pool create txg:5] pool spa 28; zfs spa 28; zpl 5;uts  9.1-RELEASE 901000 amd64
2013-02-27.18:50:53 <span class="o">[</span>internal property <span class="nb">set </span>txg:50] <span class="nv">atime</span><span class="o">=</span>0 dataset <span class="o">=</span> 21
2013-02-27.18:50:58 zfs <span class="nb">set </span><span class="nv">atime</span><span class="o">=</span>off tank
2013-02-27.18:51:04 <span class="o">[</span>internal property <span class="nb">set </span>txg:53] <span class="nv">checksum</span><span class="o">=</span>7 dataset <span class="o">=</span> 21
2013-02-27.18:51:09 zfs <span class="nb">set </span><span class="nv">checksum</span><span class="o">=</span>fletcher4 tank
2013-02-27.18:51:13 <span class="o">[</span>internal create txg:55] dataset <span class="o">=</span> 39
2013-02-27.18:51:18 zfs create tank/backup</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过添加 <code>-l</code> 来显示更多详细信息。以长格式显示历史记录，包括发出命令的用户的名称和发生更改的主机名。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool history -l</span>
History <span class="k">for</span> <span class="s1">&#39;tank&#39;</span>:
2013-02-26.23:02:35 zpool create tank mirror /dev/ada0 /dev/ada1 <span class="o">[</span>user 0 <span class="o">(</span>root<span class="o">)</span> on :global]
2013-02-27.18:50:58 zfs <span class="nb">set </span><span class="nv">atime</span><span class="o">=</span>off tank <span class="o">[</span>user 0 <span class="o">(</span>root<span class="o">)</span> on myzfsbox:global]
2013-02-27.18:51:09 zfs <span class="nb">set </span><span class="nv">checksum</span><span class="o">=</span>fletcher4 tank <span class="o">[</span>user 0 <span class="o">(</span>root<span class="o">)</span> on myzfsbox:global]
2013-02-27.18:51:18 zfs create tank/backup <span class="o">[</span>user 0 <span class="o">(</span>root<span class="o">)</span> on myzfsbox:global]</code></pre>
</div>
</div>
<div class="paragraph">
<p>输出显示 <code>root</code> 用户使用磁盘 <span class="filename">/dev/ada0</span> 和 <span class="filename">/dev/ada1</span> 创建了镜像池。在池创建后的命令中还显示了主机名 <code>myzfsbox</code> 。主机名的显示在将池从一个系统导出并在另一个系统导入时变得重要。可以通过为每个命令记录的主机名来区分在另一个系统上发出的命令。</p>
</div>
<div class="paragraph">
<p>将两个选项 <code>zpool history</code> 结合起来，以便为任何给定的池提供尽可能详细的信息。池历史记录在追踪执行的操作或需要更详细的输出进行调试时提供有价值的信息。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-iostat">22.3.13. 性能监控<a class="anchor" href="#zfs-zpool-iostat"></a></h3>
<div class="paragraph">
<p>内置的监控系统可以实时显示池的 I/O 统计信息。它显示池中的可用空间和已使用空间的数量，每秒执行的读写操作次数以及使用的 I/O 带宽。默认情况下， ZFS 监视并显示系统中的所有池。提供池名称以限制监控到该池。一个基本示例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool iostat</span>
               capacity     operations    bandwidth
pool        alloc   free   <span class="nb">read  </span>write   <span class="nb">read  </span>write
----------  -----  -----  -----  -----  -----  -----
data         288G  1.53T      2     11  11.3K  57.1K</code></pre>
</div>
</div>
<div class="paragraph">
<p>要持续查看 I/O 活动，请在最后一个参数中指定一个数字，表示更新之间等待的秒数间隔。每个间隔后都会打印下一个统计行。按下 <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span> 停止此连续监视。在间隔之后的命令行上给出第二个数字，以指定要显示的统计总数。</p>
</div>
<div class="paragraph">
<p>使用 <code>-v</code> 参数可以显示更详细的 I/O 统计信息。池中的每个设备都会显示一行统计信息。这对于查看在每个设备上执行的读写操作非常有用，并且可以帮助确定是否有任何单个设备导致池变慢。以下示例显示了一个具有两个设备的镜像池。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool iostat -v</span>
                            capacity     operations    bandwidth
pool                     alloc   free   <span class="nb">read  </span>write   <span class="nb">read  </span>write
-----------------------  -----  -----  -----  -----  -----  -----
data                      288G  1.53T      2     12  9.23K  61.5K
  mirror                  288G  1.53T      2     12  9.23K  61.5K
    ada1                     -      -      0      4  5.61K  61.7K
    ada2                     -      -      1      4  5.04K  61.7K
-----------------------  -----  -----  -----  -----  -----  -----</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zpool-split">22.3.14. 分割存储池<a class="anchor" href="#zfs-zpool-split"></a></h3>
<div class="paragraph">
<p>ZFS 可以将由一个或多个镜像 vdev 组成的池分割成两个池。除非另有指定，ZFS 会分离每个镜像的最后一个成员，并创建一个包含相同数据的新池。请务必先使用 <code>-n</code> 进行试运行。这将显示所请求操作的详细信息，但不会实际执行操作。这有助于确认操作是否符合用户的意图。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-zfs">22.4. <code>zfs</code> 管理<a class="anchor" href="#zfs-zfs"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>zfs</code> 实用程序可以在池中创建、销毁和管理所有现有的 ZFS 数据集。要管理池本身，请使用 <code>zpool</code>。</p>
</div>
<div class="sect2">
<h3 id="zfs-zfs-create">22.4.1. 创建和销毁数据集<a class="anchor" href="#zfs-zfs-create"></a></h3>
<div class="paragraph">
<p>与传统的磁盘和卷管理器不同，ZFS 中的空间是 <em>不预分配</em> 的。在传统文件系统中，分区和分配空间后，无法在不添加新磁盘的情况下添加新的文件系统。而在 ZFS 中，可以随时创建新的文件系统。每个 <a href="#zfs-term-dataset">数据集 </a> 都有属性，包括压缩、去重、缓存和配额等功能，以及其他有用的属性，如只读、大小写敏感、网络文件共享和挂载点。可以将数据集嵌套在彼此之间，并且子数据集将继承其祖先的属性。 <a href="#zfs-zfs-allow ">委派 </a>、<a href="#zfs-zfs-send ">复制 </a>、<a href="#zfs-zfs-snapshot ">快照 </a>、<a href="#zfs-zfs-jail ">监狱</a> 允许将每个数据集作为一个单元进行管理和销毁。为每种不同类型或文件集创建单独的数据集具有优势。拥有大量数据集的缺点是，某些命令（如 <code>zfs list</code>）的速度会变慢，并且挂载数百甚至数千个数据集会减慢 FreeBSD 的启动过程。</p>
</div>
<div class="paragraph">
<p>创建一个新的数据集，并在其上启用 LZ4 压缩。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list</span>
NAME                  USED  AVAIL  REFER  MOUNTPOINT
mypool                781M  93.2G   144K  none
mypool/ROOT           777M  93.2G   144K  none
mypool/ROOT/default   777M  93.2G   777M  /
mypool/tmp            176K  93.2G   176K  /tmp
mypool/usr            616K  93.2G   144K  /usr
mypool/usr/home       184K  93.2G   184K  /usr/home
mypool/usr/ports      144K  93.2G   144K  /usr/ports
mypool/usr/src        144K  93.2G   144K  /usr/src
mypool/var           1.20M  93.2G   608K  /var
mypool/var/crash      148K  93.2G   148K  /var/crash
mypool/var/log        178K  93.2G   178K  /var/log
mypool/var/mail       144K  93.2G   144K  /var/mail
mypool/var/tmp        152K  93.2G   152K  /var/tmp
<span class="c"># zfs create -o compress=lz4 mypool/usr/mydataset</span>
<span class="c"># zfs list</span>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
mypool                 781M  93.2G   144K  none
mypool/ROOT            777M  93.2G   144K  none
mypool/ROOT/default    777M  93.2G   777M  /
mypool/tmp             176K  93.2G   176K  /tmp
mypool/usr             704K  93.2G   144K  /usr
mypool/usr/home        184K  93.2G   184K  /usr/home
mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset
mypool/usr/ports       144K  93.2G   144K  /usr/ports
mypool/usr/src         144K  93.2G   144K  /usr/src
mypool/var            1.20M  93.2G   610K  /var
mypool/var/crash       148K  93.2G   148K  /var/crash
mypool/var/log         178K  93.2G   178K  /var/log
mypool/var/mail        144K  93.2G   144K  /var/mail
mypool/var/tmp         152K  93.2G   152K  /var/tmp</code></pre>
</div>
</div>
<div class="paragraph">
<p>销毁数据集比删除数据集上的文件要快得多，因为它不涉及扫描文件和更新相应的元数据。</p>
</div>
<div class="paragraph">
<p>销毁已创建的数据集：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list</span>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
mypool                 880M  93.1G   144K  none
mypool/ROOT            777M  93.1G   144K  none
mypool/ROOT/default    777M  93.1G   777M  /
mypool/tmp             176K  93.1G   176K  /tmp
mypool/usr             101M  93.1G   144K  /usr
mypool/usr/home        184K  93.1G   184K  /usr/home
mypool/usr/mydataset   100M  93.1G   100M  /usr/mydataset
mypool/usr/ports       144K  93.1G   144K  /usr/ports
mypool/usr/src         144K  93.1G   144K  /usr/src
mypool/var            1.20M  93.1G   610K  /var
mypool/var/crash       148K  93.1G   148K  /var/crash
mypool/var/log         178K  93.1G   178K  /var/log
mypool/var/mail        144K  93.1G   144K  /var/mail
mypool/var/tmp         152K  93.1G   152K  /var/tmp
<span class="c"># zfs destroy mypool/usr/mydataset</span>
<span class="c"># zfs list</span>
NAME                  USED  AVAIL  REFER  MOUNTPOINT
mypool                781M  93.2G   144K  none
mypool/ROOT           777M  93.2G   144K  none
mypool/ROOT/default   777M  93.2G   777M  /
mypool/tmp            176K  93.2G   176K  /tmp
mypool/usr            616K  93.2G   144K  /usr
mypool/usr/home       184K  93.2G   184K  /usr/home
mypool/usr/ports      144K  93.2G   144K  /usr/ports
mypool/usr/src        144K  93.2G   144K  /usr/src
mypool/var           1.21M  93.2G   612K  /var
mypool/var/crash      148K  93.2G   148K  /var/crash
mypool/var/log        178K  93.2G   178K  /var/log
mypool/var/mail       144K  93.2G   144K  /var/mail
mypool/var/tmp        152K  93.2G   152K  /var/tmp</code></pre>
</div>
</div>
<div class="paragraph">
<p>在现代版本的 ZFS 中， <code>zfs destroy</code> 是异步的，释放的空间可能需要几分钟才会在池中显示出来。使用 <code>zpool get freeing <em>poolname</em></code> 命令来查看 <code>freeing</code> 属性，该属性显示了哪些数据集正在后台释放其块。如果存在子数据集，例如快照或其他数据集，那么无法销毁父数据集。要销毁一个数据集及其子数据集，可以使用 <code>-r</code> 选项递归地销毁数据集及其子数据集。使用 <code>-n -v</code> 选项列出此操作销毁的数据集和快照，而不实际销毁任何内容。销毁快照释放的空间也会显示出来。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-volume">22.4.2. 创建和销毁卷<a class="anchor" href="#zfs-zfs-volume"></a></h3>
<div class="paragraph">
<p>卷是一种特殊的数据集类型。它不像文件系统那样挂载，而是在 <code>/dev/zvol/poolname/dataset</code> 下以块设备的形式公开。这使得可以将卷用于其他文件系统，用于虚拟机的磁盘备份，或者通过 iSCSI 或 HAST 等协议使其对其他网络主机可用。</p>
</div>
<div class="paragraph">
<p>使用任何文件系统或者不使用文件系统来格式化一个卷，以存储原始数据。对于用户来说，一个卷看起来就像一个普通的磁盘。在这些 <em>zvol</em> 上放置普通的文件系统提供了普通磁盘或文件系统所没有的功能。例如，使用压缩属性在一个 250MB 的卷上可以创建一个压缩的 FAT 文件系统。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs create -V 250m -o compression=on tank/fat32</span>
<span class="c"># zfs list tank</span>
NAME USED AVAIL REFER MOUNTPOINT
tank 258M  670M   31K /tank
<span class="c"># newfs_msdos -F32 /dev/zvol/tank/fat32</span>
<span class="c"># mount -t msdosfs /dev/zvol/tank/fat32 /mnt</span>
<span class="c"># df -h /mnt | grep fat32</span>
Filesystem           Size Used Avail Capacity Mounted on
/dev/zvol/tank/fat32 249M  24k  249M     0%   /mnt
<span class="c"># mount | grep fat32</span>
/dev/zvol/tank/fat32 on /mnt <span class="o">(</span>msdosfs, <span class="nb">local</span><span class="o">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>销毁一个卷与销毁一个常规文件系统数据集基本相同。该操作几乎是瞬时完成的，但在后台重新获取空闲空间可能需要几分钟的时间。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-rename">22.4.3. 重命名数据集<a class="anchor" href="#zfs-zfs-rename"></a></h3>
<div class="paragraph">
<p>要更改数据集的名称，请使用 <code>zfs rename</code> 命令。要更改数据集的父级，请同样使用此命令。将数据集重命名为具有不同父级的数据集将更改从父级数据集继承的属性的值。将数据集重命名为新位置（从新父级数据集继承）将卸载然后重新挂载它。要防止此行为，请使用 <code>-u</code> 选项。</p>
</div>
<div class="paragraph">
<p>重命名数据集并将其移动到不同的父数据集下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list</span>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
mypool                 780M  93.2G   144K  none
mypool/ROOT            777M  93.2G   144K  none
mypool/ROOT/default    777M  93.2G   777M  /
mypool/tmp             176K  93.2G   176K  /tmp
mypool/usr             704K  93.2G   144K  /usr
mypool/usr/home        184K  93.2G   184K  /usr/home
mypool/usr/mydataset  87.5K  93.2G  87.5K  /usr/mydataset
mypool/usr/ports       144K  93.2G   144K  /usr/ports
mypool/usr/src         144K  93.2G   144K  /usr/src
mypool/var            1.21M  93.2G   614K  /var
mypool/var/crash       148K  93.2G   148K  /var/crash
mypool/var/log         178K  93.2G   178K  /var/log
mypool/var/mail        144K  93.2G   144K  /var/mail
mypool/var/tmp         152K  93.2G   152K  /var/tmp
<span class="c"># zfs rename mypool/usr/mydataset mypool/var/newname</span>
<span class="c"># zfs list</span>
NAME                  USED  AVAIL  REFER  MOUNTPOINT
mypool                780M  93.2G   144K  none
mypool/ROOT           777M  93.2G   144K  none
mypool/ROOT/default   777M  93.2G   777M  /
mypool/tmp            176K  93.2G   176K  /tmp
mypool/usr            616K  93.2G   144K  /usr
mypool/usr/home       184K  93.2G   184K  /usr/home
mypool/usr/ports      144K  93.2G   144K  /usr/ports
mypool/usr/src        144K  93.2G   144K  /usr/src
mypool/var           1.29M  93.2G   614K  /var
mypool/var/crash      148K  93.2G   148K  /var/crash
mypool/var/log        178K  93.2G   178K  /var/log
mypool/var/mail       144K  93.2G   144K  /var/mail
mypool/var/newname   87.5K  93.2G  87.5K  /var/newname
mypool/var/tmp        152K  93.2G   152K  /var/tmp</code></pre>
</div>
</div>
<div class="paragraph">
<p>重命名快照使用相同的命令。由于快照的特性，重命名不能改变它们的父数据集。要重命名递归快照，请指定 <code>-r</code> ；这也会重命名所有子数据集中具有相同名称的快照。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -t snapshot</span>
NAME                                USED  AVAIL  REFER  MOUNTPOINT
mypool/var/newname@first_snapshot      0      -  87.5K  -
<span class="c"># zfs rename mypool/var/newname@first_snapshot new_snapshot_name</span>
<span class="c"># zfs list -t snapshot</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/newname@new_snapshot_name      0      -  87.5K  -</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-set">22.4.4. 设置数据集属性<a class="anchor" href="#zfs-zfs-set"></a></h3>
<div class="paragraph">
<p>每个 ZFS 数据集都有控制其行为的属性。大多数属性会自动从父数据集继承，但可以在本地进行覆盖。使用 <code>zfs set <em>property=value dataset</em></code> 在数据集上设置属性。大多数属性有一组有限的有效值，<code>zfs get</code> 将显示每个可能的属性和有效值。使用 <code>zfs inherit</code> 将大多数属性恢复为其继承的值。还可以定义用户自定义属性。它们成为数据集配置的一部分，并提供有关数据集或其内容的进一步信息。为了区分这些自定义属性和作为 ZFS 的一部分提供的属性，可以使用冒号（<code>:</code>）为属性创建自定义命名空间。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set custom:costcenter=1234 tank</span>
<span class="c"># zfs get custom:costcenter tank</span>
NAME PROPERTY           VALUE SOURCE
tank custom:costcenter  1234  <span class="nb">local</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要删除自定义属性，请使用 <code>zfs inherit</code> 命令并加上 <code>-r</code> 选项。如果自定义属性在任何父数据集中都没有定义，这个选项将删除它（但池的历史记录仍然会记录这个更改）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs inherit -r custom:costcenter tank</span>
<span class="c"># zfs get custom:costcenter tank</span>
NAME    PROPERTY           VALUE              SOURCE
tank    custom:costcenter  -                  -
<span class="c"># zfs get all tank | grep custom:costcenter</span>
<span class="c">#</span></code></pre>
</div>
</div>
<div class="sect3">
<h4 id="zfs-zfs-set-share">22.4.4.1. 获取和设置共享属性<a class="anchor" href="#zfs-zfs-set-share"></a></h4>
<div class="paragraph">
<p>两个常用且有用的数据集属性是 NFS 和 SMB 共享选项。设置这些选项可以定义 ZFS 在网络上共享数据集的方式和方式。目前，FreeBSD 仅支持设置 NFS 共享。要获取共享的当前状态，请输入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get sharenfs mypool/usr/home</span>
NAME             PROPERTY  VALUE    SOURCE
mypool/usr/home  sharenfs  on       <span class="nb">local</span>
<span class="c"># zfs get sharesmb mypool/usr/home</span>
NAME             PROPERTY  VALUE    SOURCE
mypool/usr/home  sharesmb  off      <span class="nb">local</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>要启用数据集的共享，请输入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c">#  zfs set sharenfs=on mypool/usr/home</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>设置通过 NFS 共享数据集的其他选项，例如 <code>-alldirs</code>、<code>-maproot</code> 和 <code>-network</code>。要在通过 NFS 共享的数据集上设置选项，请输入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c">#  zfs set sharenfs=&#34;-alldirs,-maproot=root,-network=192.168.1.0/24&#34; mypool/usr/home</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-snapshot">22.4.5. 管理快照<a class="anchor" href="#zfs-zfs-snapshot"></a></h3>
<div class="paragraph">
<p><a href="#zfs-term-snapshot">快照</a> 是 ZFS 最强大的功能之一。快照提供了数据集的只读、时间点的副本。通过写时复制（COW），ZFS 通过在磁盘上保留旧版本的数据来快速创建快照。如果没有快照存在，当数据被重写或删除时，ZFS 会回收空间以供将来使用。快照通过记录当前数据集与先前版本之间的差异来保留磁盘空间。允许在整个数据集上进行快照，而不是在单个文件或目录上进行快照。数据集的快照复制其中包含的所有内容。这包括文件系统属性、文件、目录、权限等。快照在创建时不占用额外的空间，但随着它们引用的块的变化而消耗空间。使用 <code>-r</code> 进行递归快照会在数据集及其子数据集上创建具有相同名称的快照，提供文件系统的一致时刻快照。当应用程序在相关数据集上有文件或相互依赖时，这可能很重要。如果没有快照，备份将具有来自不同时间点的文件副本。</p>
</div>
<div class="paragraph">
<p>ZFS 中的快照提供了许多其他具有快照功能的文件系统所缺乏的功能。快照的典型用法是在执行风险操作（如软件安装或系统升级）时，快速备份文件系统的当前状态。如果操作失败，回滚到快照可以将系统恢复到创建快照时的相同状态。如果升级成功，可以删除快照以释放空间。如果没有快照，升级失败通常需要恢复备份，这是繁琐、耗时的，并且可能需要停机时间，期间系统无法使用。回滚到快照是快速的，即使系统在正常运行中，几乎没有停机时间。考虑到从备份中复制数据所需的时间，对于多 TB 存储系统来说，节省的时间是巨大的。快照不能替代对池的完整备份，但提供了一种快速简便的方式来存储特定时间点的数据集副本。</p>
</div>
<div class="sect3">
<h4 id="zfs-zfs-snapshot-creation">22.4.5.1. 创建快照<a class="anchor" href="#zfs-zfs-snapshot-creation"></a></h4>
<div class="paragraph">
<p>要创建快照，请使用 <code>zfs snapshot <em>dataset</em>@<em>snapshotname</em></code> 命令。添加 <code>-r</code> 选项可以递归地创建快照，并在所有子数据集上使用相同的名称。</p>
</div>
<div class="paragraph">
<p>创建整个池的递归快照：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -t all</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool                                 780M  93.2G   144K  none
mypool/ROOT                            777M  93.2G   144K  none
mypool/ROOT/default                    777M  93.2G   777M  /
mypool/tmp                             176K  93.2G   176K  /tmp
mypool/usr                             616K  93.2G   144K  /usr
mypool/usr/home                        184K  93.2G   184K  /usr/home
mypool/usr/ports                       144K  93.2G   144K  /usr/ports
mypool/usr/src                         144K  93.2G   144K  /usr/src
mypool/var                            1.29M  93.2G   616K  /var
mypool/var/crash                       148K  93.2G   148K  /var/crash
mypool/var/log                         178K  93.2G   178K  /var/log
mypool/var/mail                        144K  93.2G   144K  /var/mail
mypool/var/newname                    87.5K  93.2G  87.5K  /var/newname
mypool/var/newname@new_snapshot_name      0      -  87.5K  -
mypool/var/tmp                         152K  93.2G   152K  /var/tmp
<span class="c"># zfs snapshot -r mypool@my_recursive_snapshot</span>
<span class="c"># zfs list -t snapshot</span>
NAME                                        USED  AVAIL  REFER  MOUNTPOINT
mypool@my_recursive_snapshot                   0      -   144K  -
mypool/ROOT@my_recursive_snapshot              0      -   144K  -
mypool/ROOT/default@my_recursive_snapshot      0      -   777M  -
mypool/tmp@my_recursive_snapshot               0      -   176K  -
mypool/usr@my_recursive_snapshot               0      -   144K  -
mypool/usr/home@my_recursive_snapshot          0      -   184K  -
mypool/usr/ports@my_recursive_snapshot         0      -   144K  -
mypool/usr/src@my_recursive_snapshot           0      -   144K  -
mypool/var@my_recursive_snapshot               0      -   616K  -
mypool/var/crash@my_recursive_snapshot         0      -   148K  -
mypool/var/log@my_recursive_snapshot           0      -   178K  -
mypool/var/mail@my_recursive_snapshot          0      -   144K  -
mypool/var/newname@new_snapshot_name           0      -  87.5K  -
mypool/var/newname@my_recursive_snapshot       0      -  87.5K  -
mypool/var/tmp@my_recursive_snapshot           0      -   152K  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>普通的 <code>zfs list</code> 操作不会显示快照。要列出快照，请在 <code>zfs list</code> 后面添加 <code>-t snapshot</code>。 <code>-t all</code> 可以同时显示文件系统和快照。</p>
</div>
<div class="paragraph">
<p>快照不会直接挂载，因此在 <code>MOUNTPOINT</code> 列中不显示路径。ZFS 在 <code>AVAIL</code> 列中不提及可用磁盘空间，因为快照在创建后是只读的。将快照与原始数据集进行比较：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -rt all mypool/usr/home</span>
NAME                                    USED  AVAIL  REFER  MOUNTPOINT
mypool/usr/home                         184K  93.2G   184K  /usr/home
mypool/usr/home@my_recursive_snapshot      0      -   184K  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>同时显示数据集和快照可以展示快照以 <a href="#zfs-term-cow">写时复制</a> 方式工作的原理。它们保存所做的更改（<em>delta</em>），而不是再次保存完整的文件系统内容。这意味着在进行更改时，快照所占用的空间很小。通过将文件复制到数据集中，然后创建第二个快照，可以更加观察空间使用情况：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp /etc/passwd /var/tmp</span>
<span class="c"># zfs snapshot mypool/var/tmp@after_cp</span>
<span class="c"># zfs list -rt all mypool/var/tmp</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/tmp                         206K  93.2G   118K  /var/tmp
mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -
mypool/var/tmp@after_cp                   0      -   118K  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>第二个快照包含了复制操作后数据集的变化。这样可以节省大量的空间。请注意，快照 <code><em>mypool/var/tmp@my_recursive_snapshot</em></code> 的大小在 <code>USED</code> 列中也发生了变化，以显示它与之后拍摄的快照之间的变化。</p>
</div>
</div>
<div class="sect3">
<h4 id="zfs-zfs-snapshot-diff">22.4.5.2. 比较快照<a class="anchor" href="#zfs-zfs-snapshot-diff"></a></h4>
<div class="paragraph">
<p>ZFS 提供了一个内置命令，用于比较两个快照之间内容的差异。当用户想要查看文件系统随时间变化的方式时，这非常有帮助，尤其是在有很多快照的情况下。例如， <code>zfs diff</code> 命令可以帮助用户找到最新的快照，其中仍然包含了意外删除的文件。对于前一节创建的两个快照，执行此命令将输出如下结果：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -rt all mypool/var/tmp</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/tmp                         206K  93.2G   118K  /var/tmp
mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -
mypool/var/tmp@after_cp                   0      -   118K  -
<span class="c"># zfs diff mypool/var/tmp@my_recursive_snapshot</span>
M       /var/tmp/
+       /var/tmp/passwd</code></pre>
</div>
</div>
<div class="paragraph">
<p>该命令列出了指定快照（在本例中为 <code><em>mypool/var/tmp@my_recursive_snapshot</em></code> ）与活动文件系统之间的变化。第一列显示变化类型：</p>
</div>
<table class="tableblock frame-all grid-all stretch informaltable">
<colgroup>
<col style="width: 20%;"/>
<col style="width: 80%;"/>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">添加路径或文件。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">删除路径或文件。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">M</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">修改路径或文件。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">R</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">重命名路径或文件。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>将输出与表格进行比较，可以清楚地看到 ZFS 在创建快照 <code><em>mypool/var/tmp@my_recursive_snapshot</em></code> 之后添加了 <span class="filename">passwd</span> 。这也导致了挂载在 <code><em>/var/tmp</em></code> 上的父目录的修改。</p>
</div>
<div class="paragraph">
<p>当使用 ZFS 复制功能将数据集传输到不同的主机进行备份时，比较两个快照是非常有帮助的。</p>
</div>
<div class="paragraph">
<p>通过提供两个数据集的完整数据集名称和快照名称来比较两个快照：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp /var/tmp/passwd /var/tmp/passwd.copy</span>
<span class="c"># zfs snapshot mypool/var/tmp@diff_snapshot</span>
<span class="c"># zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@diff_snapshot</span>
M       /var/tmp/
+       /var/tmp/passwd
+       /var/tmp/passwd.copy
<span class="c"># zfs diff mypool/var/tmp@my_recursive_snapshot mypool/var/tmp@after_cp</span>
M       /var/tmp/
+       /var/tmp/passwd</code></pre>
</div>
</div>
<div class="paragraph">
<p>备份管理员可以比较从发送主机接收到的两个快照，并确定数据集中的实际更改。有关更多信息，请参阅 <a href="#zfs-zfs-send">复制 </a> 部分。</p>
</div>
</div>
<div class="sect3">
<h4 id="zfs-zfs-snapshot-rollback">22.4.5.3. 快照回滚<a class="anchor" href="#zfs-zfs-snapshot-rollback"></a></h4>
<div class="paragraph">
<p>当至少有一个快照可用时，随时可以回滚到该快照。大多数情况下，当数据集的当前状态不再存在或者更喜欢旧版本时，会出现这种情况。诸如本地开发测试失败、系统更新失败导致系统功能受阻，或者需要恢复已删除的文件或目录等情况都很常见。要回滚快照，请使用 <code>zfs rollback <em>snapshotname</em></code> 命令。如果存在大量更改，操作将需要很长时间。在此期间，数据集始终保持一致的状态，就像符合 ACID 原则的数据库执行回滚操作一样。这一切都发生在数据集处于活动状态且可访问的情况下，无需停机。一旦快照回滚完成，数据集的状态与快照创建时的状态相同。回滚到快照会丢弃数据集中不属于该快照的所有其他数据。在回滚到以前的快照之前，将当前数据集的状态进行快照是一个好主意，以便稍后需要某些数据。这样，用户可以在快照之间来回切换，而不会丢失仍然有价值的数据。</p>
</div>
<div class="paragraph">
<p>在第一个示例中，由于一个粗心的 <code>rm</code> 操作删除了比预期更多的数据，因此需要回滚一个快照。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -rt all mypool/var/tmp</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/tmp                         262K  93.2G   120K  /var/tmp
mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -
mypool/var/tmp@after_cp               53.5K      -   118K  -
mypool/var/tmp@diff_snapshot              0      -   120K  -
<span class="c"># ls /var/tmp</span>
passwd          passwd.copy     vi.recover
<span class="c"># rm /var/tmp/passwd*</span>
<span class="c"># ls /var/tmp</span>
vi.recover</code></pre>
</div>
</div>
<div class="paragraph">
<p>在这一点上，用户注意到额外文件被删除了，并希望将它们恢复。 ZFS 提供了一种简单的方法来使用回滚将它们恢复，当定期对重要数据进行快照时。要将文件恢复并从最后一个快照重新开始，执行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs rollback mypool/var/tmp@diff_snapshot</span>
<span class="c"># ls /var/tmp</span>
passwd          passwd.copy     vi.recover</code></pre>
</div>
</div>
<div class="paragraph">
<p>回滚操作将数据集恢复到最后一个快照的状态。也可以回滚到之前拍摄的快照之后拍摄的其他快照的状态。在尝试这样做时，ZFS 会发出以下警告：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -rt snapshot mypool/var/tmp</span>
AME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/tmp@my_recursive_snapshot    88K      -   152K  -
mypool/var/tmp@after_cp               53.5K      -   118K  -
mypool/var/tmp@diff_snapshot              0      -   120K  -
<span class="c"># zfs rollback mypool/var/tmp@my_recursive_snapshot</span>
cannot rollback to <span class="s1">&#39;mypool/var/tmp@my_recursive_snapshot&#39;</span>: more recent snapshots exist
use <span class="s1">&#39;-r&#39;</span> to force deletion of the following snapshots:
mypool/var/tmp@after_cp
mypool/var/tmp@diff_snapshot</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个警告意味着在当前数据集状态和用户想要回滚的快照之间存在快照。要完成回滚操作，请删除这些快照。由于快照是只读的，ZFS 无法跟踪数据集不同状态之间的所有更改。除非用户使用 <code>-r</code> 参数确认这是所需的操作，否则 ZFS 不会删除受影响的快照。如果这是用户的意图，并且理解丢失所有中间快照的后果，请执行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs rollback -r mypool/var/tmp@my_recursive_snapshot</span>
<span class="c"># zfs list -rt snapshot mypool/var/tmp</span>
NAME                                   USED  AVAIL  REFER  MOUNTPOINT
mypool/var/tmp@my_recursive_snapshot     8K      -   152K  -
<span class="c"># ls /var/tmp</span>
vi.recover</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>zfs list -t snapshot</code> 的输出确认了由于 <code>zfs rollback -r</code> 的结果，中间快照已被删除。</p>
</div>
</div>
<div class="sect3">
<h4 id="zfs-zfs-snapshot-snapdir">22.4.5.4. 从快照中恢复单个文件<a class="anchor" href="#zfs-zfs-snapshot-snapdir"></a></h4>
<div class="paragraph">
<p>快照存储在父数据集的隐藏目录下： <span class="filename">.zfs/snapshots/snapshotname</span> 。默认情况下，即使执行标准的 <code>ls -a</code> 命令，这些目录也不会显示出来。尽管目录不可见，但可以像访问普通目录一样访问它。名为 <code>snapdir</code> 的属性控制这些隐藏目录是否在目录列表中显示。将该属性设置为 <code>visible</code> 可以使它们出现在 <code>ls</code> 和其他处理目录内容的命令的输出中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get snapdir mypool/var/tmp</span>
NAME            PROPERTY  VALUE    SOURCE
mypool/var/tmp  snapdir   hidden   default
<span class="c"># ls -a /var/tmp</span>
.               ..              passwd          vi.recover
<span class="c"># zfs set snapdir=visible mypool/var/tmp</span>
<span class="c"># ls -a /var/tmp</span>
.               ..              .zfs            passwd          vi.recover</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过将文件从快照复制回父数据集，将其恢复到先前的状态。 <span class="filename">.zfs/snapshot</span> 下的目录结构中有一个类似于先前拍摄的快照的目录，以便更容易识别它们。下一个示例显示了如何从隐藏的 <span class="filename">.zfs</span> 目录中复制文件，从包含文件最新版本的快照中恢复文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># rm /var/tmp/passwd</span>
<span class="c"># ls -a /var/tmp</span>
.               ..              .zfs            vi.recover
<span class="c"># ls /var/tmp/.zfs/snapshot</span>
after_cp                my_recursive_snapshot
<span class="c"># ls /var/tmp/.zfs/snapshot/after_cp</span>
passwd          vi.recover
<span class="c"># cp /var/tmp/.zfs/snapshot/after_cp/passwd /var/tmp</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>即使将 <code>snapdir</code> 属性设置为隐藏，运行 <code>ls .zfs/snapshot</code> 仍然会列出该目录的内容。管理员决定是否显示这些目录。这是每个数据集的设置。从这个隐藏的 <span class="filename">.zfs/snapshot</span> 复制文件或目录非常简单。尝试反过来操作会导致以下错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp /etc/rc.conf /var/tmp/.zfs/snapshot/after_cp/</span>
cp: /var/tmp/.zfs/snapshot/after_cp/rc.conf: Read-only file system</code></pre>
</div>
</div>
<div class="paragraph">
<p>该错误提醒用户快照是只读的，创建后不能更改。将文件复制到快照目录或从中删除文件都是不允许的，因为这会改变所表示数据集的状态。</p>
</div>
<div class="paragraph">
<p>快照占用的空间取决于父文件系统自快照以来的更改量。快照的 <code>written</code> 属性跟踪快照使用的空间。</p>
</div>
<div class="paragraph">
<p>要销毁快照并回收空间，请使用 <code>zfs destroy <em>dataset</em>@<em>snapshot</em></code> 命令。添加 <code>-r</code> 选项可以递归删除父数据集下具有相同名称的所有快照。在命令中添加 <code>-n -v</code> 选项可以显示要删除的快照列表以及执行实际销毁操作前将回收的空间的估计值。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-clones">22.4.6. 管理克隆实例<a class="anchor" href="#zfs-zfs-clones"></a></h3>
<div class="paragraph">
<p>克隆是快照的副本，更像一个常规数据集。与快照不同，克隆是可写的和可挂载的，并且具有自己的属性。使用 <code>zfs clone</code> 创建克隆后，无法销毁原始快照。要反转克隆和快照之间的子/父关系，请使用 <code>zfs promote</code> 。将克隆提升为快照成为克隆的子项，而不是原始父数据集的子项。这将改变 ZFS 对空间的计算方式，但实际上不会改变所消耗的空间量。可以在 ZFS 文件系统层次结构中的任何位置挂载克隆，不仅限于快照的原始位置下方。</p>
</div>
<div class="paragraph">
<p>要展示克隆功能，请使用以下示例数据集：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs list -rt all camino/home/joe</span>
NAME                    USED  AVAIL  REFER  MOUNTPOINT
camino/home/joe         108K   1.3G    87K  /usr/home/joe
camino/home/joe@plans    21K      -  85.5K  -
camino/home/joe@backup    0K      -    87K  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>克隆的典型用途是在进行特定数据集的实验时，保留快照以备不时之需。由于快照是不可更改的，因此需要创建一个可读/写的快照克隆。在克隆中获得所需的结果后，将克隆提升为数据集并删除旧的文件系统。严格来说，删除父数据集并非必需，因为克隆和数据集可以共存而不会出现问题。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs clone camino/home/joe@backup camino/home/joenew</span>
<span class="c"># ls /usr/home/joe*</span>
/usr/home/joe:
backup.txz     plans.txt

/usr/home/joenew:
backup.txz     plans.txt
<span class="c"># df -h /usr/home</span>
Filesystem          Size    Used   Avail Capacity  Mounted on
usr/home/joe        1.3G     31k    1.3G     0%    /usr/home/joe
usr/home/joenew     1.3G     31k    1.3G     0%    /usr/home/joenew</code></pre>
</div>
</div>
<div class="paragraph">
<p>创建克隆会使其成为数据集在拍摄快照时的精确副本。现在可以独立地更改克隆与其源数据集之间的连接。两者之间的连接是快照。 ZFS 将此连接记录在属性 <code>origin</code> 中。使用 <code>zfs promote</code> 提升克隆将使其成为独立的数据集。这将删除 <code>origin</code> 属性的值，并断开新独立数据集与快照之间的连接。以下示例说明了这一点：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get origin camino/home/joenew</span>
NAME                  PROPERTY  VALUE                     SOURCE
camino/home/joenew    origin    camino/home/joe@backup    -
<span class="c"># zfs promote camino/home/joenew</span>
<span class="c"># zfs get origin camino/home/joenew</span>
NAME                  PROPERTY  VALUE   SOURCE
camino/home/joenew    origin    -       -</code></pre>
</div>
</div>
<div class="paragraph">
<p>在进行一些更改后，例如将 <span class="filename">loader.conf</span> 复制到推广的克隆中，旧目录在这种情况下变得过时。相反，推广的克隆可以替代它。为了做到这一点，首先使用 <code>zfs destroy</code> 命令销毁旧数据集，然后使用 <code>zfs rename</code> 命令将克隆重命名为旧数据集的名称（或完全不同的名称）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># cp /boot/defaults/loader.conf /usr/home/joenew</span>
<span class="c"># zfs destroy -f camino/home/joe</span>
<span class="c"># zfs rename camino/home/joenew camino/home/joe</span>
<span class="c"># ls /usr/home/joe</span>
backup.txz     loader.conf     plans.txt
<span class="c"># df -h /usr/home</span>
Filesystem          Size    Used   Avail Capacity  Mounted on
usr/home/joe        1.3G    128k    1.3G     0%    /usr/home/joe</code></pre>
</div>
</div>
<div class="paragraph">
<p>克隆的快照现在是一个普通的数据集。它包含了原始快照中的所有数据，以及像 <span class="filename">loader.conf</span> 这样添加到其中的文件。在不同的场景中，克隆为 ZFS 用户提供了有用的功能。例如，可以将 jails 作为包含不同安装应用程序集的快照。用户可以克隆这些快照，并根据需要添加自己的应用程序。一旦对更改满意，可以将克隆提升为完整的数据集，并将其提供给最终用户，就像使用真实数据集一样。这样可以节省提供这些监狱时的时间和管理开销。</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-send">22.4.7. Replication<a class="anchor" href="#zfs-zfs-send"></a></h3>
<div class="paragraph">
<p>Keeping data on a single pool in one location exposes it to risks like theft and natural or human disasters. Making regular backups of the entire pool is vital. ZFS provides a built-in serialization feature that can send a stream representation of the data to standard output. Using this feature, storing this data on another pool connected to the local system is possible, as is sending it over a network to another system. Snapshots are the basis for this replication (see the section on <a href="#zfs-zfs-snapshot">ZFS snapshots</a>). The commands used for replicating data are <code>zfs send</code> and <code>zfs receive</code>.</p>
</div>
<div class="paragraph">
<p>These examples show ZFS replication with these two pools:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool list</span>
NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT
backup  960M    77K   896M         -         -     0%    0%  1.00x  ONLINE  -
mypool  984M  43.7M   940M         -         -     0%    4%  1.00x  ONLINE  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The pool named <em>mypool</em> is the primary pool where writing and reading data happens on a regular basis. Using a second standby pool <em>backup</em> in case the primary pool becomes unavailable. Note that this fail-over is not done automatically by ZFS, but must be manually done by a system administrator when needed. Use a snapshot to provide a consistent file system version to replicate. After creating a snapshot of <em>mypool</em>, copy it to the <em>backup</em> pool by replicating snapshots. This does not include changes made since the most recent snapshot.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs snapshot mypool@backup1</span>
<span class="c"># zfs list -t snapshot</span>
NAME                    USED  AVAIL  REFER  MOUNTPOINT
mypool@backup1             0      -  43.6M  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now that a snapshot exists, use <code>zfs send</code> to create a stream representing the contents of the snapshot. Store this stream as a file or receive it on another pool. Write the stream to standard output, but redirect to a file or pipe or an error appears:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs send mypool@backup1</span>
Error: Stream can not be written to a terminal.
You must redirect standard output.</code></pre>
</div>
</div>
<div class="paragraph">
<p>To back up a dataset with <code>zfs send</code>, redirect to a file located on the mounted backup pool. Ensure that the pool has enough free space to accommodate the size of the sent snapshot, which means the data contained in the snapshot, not the changes from the previous snapshot.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs send mypool@backup1 &gt; /backup/backup1</span>
<span class="c"># zpool list</span>
NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -
mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>zfs send</code> transferred all the data in the snapshot called <em>backup1</em> to the pool named <em>backup</em>. To create and send these snapshots automatically, use a <a href="https://man.freebsd.org/cgi/man.cgi?query=cron&amp;sektion=8&amp;format=html">cron(8)</a> job.</p>
</div>
<div class="paragraph">
<p>Instead of storing the backups as archive files, ZFS can receive them as a live file system, allowing direct access to the backed up data. To get to the actual data contained in those streams, use <code>zfs receive</code> to transform the streams back into files and directories. The example below combines <code>zfs send</code> and <code>zfs receive</code> using a pipe to copy the data from one pool to another. Use the data directly on the receiving pool after the transfer is complete. It is only possible to replicate a dataset to an empty dataset.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs snapshot mypool@replica1</span>
<span class="c"># zfs send -v mypool@replica1 | zfs receive backup/mypool</span>
send from @ to mypool@replica1 estimated size is 50.1M
total estimated size is 50.1M
TIME        SENT   SNAPSHOT

<span class="c"># zpool list</span>
NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
backup  960M  63.7M   896M         -         -     0%     6%  1.00x  ONLINE  -
mypool  984M  43.7M   940M         -         -     0%     4%  1.00x  ONLINE  -</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="zfs-send-incremental">22.4.7.1. Incremental Backups<a class="anchor" href="#zfs-send-incremental"></a></h4>
<div class="paragraph">
<p><code>zfs send</code> can also determine the difference between two snapshots and send individual differences between the two. This saves disk space and transfer time. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs snapshot mypool@replica2</span>
<span class="c"># zfs list -t snapshot</span>
NAME                    USED  AVAIL  REFER  MOUNTPOINT
mypool@replica1         5.72M      -  43.6M  -
mypool@replica2             0      -  44.1M  -
<span class="c"># zpool list</span>
NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG   CAP  DEDUP  HEALTH  ALTROOT
backup  960M  61.7M   898M         -         -     0%    6%  1.00x  ONLINE  -
mypool  960M  50.2M   910M         -         -     0%    5%  1.00x  ONLINE  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>Create a second snapshot called <em>replica2</em>. This second snapshot contains changes made to the file system between now and the previous snapshot, <em>replica1</em>. Using <code>zfs send -i</code> and indicating the pair of snapshots generates an incremental replica stream containing the changed data. This succeeds if the initial snapshot already exists on the receiving side.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs send -v -i mypool@replica1 mypool@replica2 | zfs receive /backup/mypool</span>
send from @replica1 to mypool@replica2 estimated size is 5.02M
total estimated size is 5.02M
TIME        SENT   SNAPSHOT

<span class="c"># zpool list</span>
NAME    SIZE  ALLOC   FREE   CKPOINT  EXPANDSZ   FRAG  CAP  DEDUP  HEALTH  ALTROOT
backup  960M  80.8M   879M         -         -     0%   8%  1.00x  ONLINE  -
mypool  960M  50.2M   910M         -         -     0%   5%  1.00x  ONLINE  -

<span class="c"># zfs list</span>
NAME                         USED  AVAIL  REFER  MOUNTPOINT
backup                      55.4M   240G   152K  /backup
backup/mypool               55.3M   240G  55.2M  /backup/mypool
mypool                      55.6M  11.6G  55.0M  /mypool

<span class="c"># zfs list -t snapshot</span>
NAME                                         USED  AVAIL  REFER  MOUNTPOINT
backup/mypool@replica1                       104K      -  50.2M  -
backup/mypool@replica2                          0      -  55.2M  -
mypool@replica1                             29.9K      -  50.0M  -
mypool@replica2                                 0      -  55.0M  -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The incremental stream replicated the changed data rather than the entirety of <em>replica1</em>. Sending the differences alone took much less time to transfer and saved disk space by not copying the whole pool each time. This is useful when replicating over a slow network or one charging per transferred byte.</p>
</div>
<div class="paragraph">
<p>A new file system, <em>backup/mypool</em>, is available with the files and data from the pool <em>mypool</em>. Specifying <code>-p</code> copies the dataset properties including compression settings, quotas, and mount points. Specifying <code>-R</code> copies all child datasets of the dataset along with their properties. Automate sending and receiving to create regular backups on the second pool.</p>
</div>
</div>
<div class="sect3">
<h4 id="zfs-send-ssh">22.4.7.2. Sending Encrypted Backups over SSH<a class="anchor" href="#zfs-send-ssh"></a></h4>
<div class="paragraph">
<p>Sending streams over the network is a good way to keep a remote backup, but it does come with a drawback. Data sent over the network link is not encrypted, allowing anyone to intercept and transform the streams back into data without the knowledge of the sending user. This is undesirable when sending the streams over the internet to a remote host. Use SSH to securely encrypt data sent over a network connection. Since ZFS requires redirecting the stream from standard output, piping it through SSH is easy. To keep the contents of the file system encrypted in transit and on the remote system, consider using <a href="https://wiki.freebsd.org/PEFS">PEFS</a>.</p>
</div>
<div class="paragraph">
<p>Change some settings and take security precautions first. This describes the necessary steps required for the <code>zfs send</code> operation; for more information on SSH, see <a href="../security/#openssh">OpenSSH</a>.</p>
</div>
<div class="paragraph">
<p>Change the configuration as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Passwordless SSH access between sending and receiving host using SSH keys</p>
</li>
<li>
<p>ZFS requires the privileges of the <code>root</code> user to send and receive streams. This requires logging in to the receiving system as <code>root</code>.</p>
</li>
<li>
<p>Security reasons prevent <code>root</code> from logging in by default.</p>
</li>
<li>
<p>Use the <a href="#zfs-zfs-allow">ZFS Delegation</a> system to allow a non-<code>root</code> user on each system to perform the respective send and receive operations. On the sending system:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs allow -u someuser send,snapshot mypool</span></code></pre>
</div>
</div>
</li>
<li>
<p>To mount the pool, the unprivileged user must own the directory, and regular users need permission to mount file systems.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>On the receiving system:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># sysctl vfs.usermount=1</span>
vfs.usermount: 0 -&gt; 1
<span class="c"># echo vfs.usermount=1 &gt;&gt; /etc/sysctl.conf</span>
<span class="c"># zfs create recvpool/backup</span>
<span class="c"># zfs allow -u someuser create,mount,receive recvpool/backup</span>
<span class="c"># chown someuser /recvpool/backup</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The unprivileged user can receive and mount datasets now, and replicates the <em>home</em> dataset to the remote system:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="gp">% </span>zfs snapshot -r mypool/home@monday
<span class="gp">% </span>zfs send -R mypool/home@monday | ssh someuser@backuphost zfs recv -dvu recvpool/backup</code></pre>
</div>
</div>
<div class="paragraph">
<p>Create a recursive snapshot called <em>monday</em> of the file system dataset <em>home</em> on the pool <em>mypool</em>. Then <code>zfs send -R</code> includes the dataset, all child datasets, snapshots, clones, and settings in the stream. Pipe the output through SSH to the waiting <code>zfs receive</code> on the remote host <em>backuphost</em>. Using an IP address or fully qualified domain name is good practice. The receiving machine writes the data to the <em>backup</em> dataset on the <em>recvpool</em> pool. Adding <code>-d</code> to <code>zfs recv</code> overwrites the name of the pool on the receiving side with the name of the snapshot. <code>-u</code> causes the file systems to not mount on the receiving side. Using <code>-v</code> shows more details about the transfer, including the elapsed time and the amount of data transferred.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-quota">22.4.8. Dataset, User, and Group Quotas<a class="anchor" href="#zfs-zfs-quota"></a></h3>
<div class="paragraph">
<p>Use <a href="#zfs-term-quota">Dataset quotas</a> to restrict the amount of space consumed by a particular dataset. <a href="#zfs-term-refquota">Reference Quotas</a> work in much the same way, but count the space used by the dataset itself, excluding snapshots and child datasets. Similarly, use <a href="#zfs-term-userquota">user</a> and <a href="#zfs-term-groupquota">group</a> quotas to prevent users or groups from using up all the space in the pool or dataset.</p>
</div>
<div class="paragraph">
<p>The following examples assume that the users already exist in the system. Before adding a user to the system, make sure to create their home dataset first and set the <code>mountpoint</code> to <code>/home/<em>bob</em></code>. Then, create the user and make the home directory point to the dataset’s <code>mountpoint</code> location. This will properly set owner and group permissions without shadowing any pre-existing home directory paths that might exist.</p>
</div>
<div class="paragraph">
<p>To enforce a dataset quota of 10 GB for <span class="filename">storage/home/bob</span>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set quota=10G storage/home/bob</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To enforce a reference quota of 10 GB for <span class="filename">storage/home/bob</span>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set refquota=10G storage/home/bob</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To remove a quota of 10 GB for <span class="filename">storage/home/bob</span>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set quota=none storage/home/bob</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The general format is <code>userquota@<em>user</em>=<em>size</em></code>, and the user’s name must be in one of these formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>POSIX compatible name such as <em>joe</em>.</p>
</li>
<li>
<p>POSIX numeric ID such as <em>789</em>.</p>
</li>
<li>
<p>SID name such as <em>joe.bloggs@example.com</em>.</p>
</li>
<li>
<p>SID numeric ID such as <em>S-1-123-456-789</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, to enforce a user quota of 50 GB for the user named <em>joe</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set userquota@joe=50G</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To remove any quota:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set userquota@joe=none</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>User quota properties are not displayed by <code>zfs get all</code>. Non-<code>root</code> users can’t see other’s quotas unless granted the <code>userquota</code> privilege. Users with this privilege are able to view and set everyone’s quota.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The general format for setting a group quota is: <code>groupquota@<em>group</em>=<em>size</em></code>.</p>
</div>
<div class="paragraph">
<p>To set the quota for the group <em>firstgroup</em> to 50 GB, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set groupquota@firstgroup=50G</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To remove the quota for the group <em>firstgroup</em>, or to make sure that one is not set, instead use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set groupquota@firstgroup=none</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>As with the user quota property, non-<code>root</code> users can see the quotas associated with the groups to which they belong. A user with the <code>groupquota</code> privilege or <code>root</code> can view and set all quotas for all groups.</p>
</div>
<div class="paragraph">
<p>To display the amount of space used by each user on a file system or snapshot along with any quotas, use <code>zfs userspace</code>. For group information, use <code>zfs groupspace</code>. For more information about supported options or how to display specific options alone, refer to <a href="https://man.freebsd.org/cgi/man.cgi?query=zfs&amp;sektion=1&amp;format=html">zfs(1)</a>.</p>
</div>
<div class="paragraph">
<p>Privileged users and <code>root</code> can list the quota for <span class="filename">storage/home/bob</span> using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get quota storage/home/bob</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-reservation">22.4.9. Reservations<a class="anchor" href="#zfs-zfs-reservation"></a></h3>
<div class="paragraph">
<p><a href="#zfs-term-reservation">Reservations</a> guarantee an always-available amount of space on a dataset. The reserved space will not be available to any other dataset. This useful feature ensures that free space is available for an important dataset or log files.</p>
</div>
<div class="paragraph">
<p>The general format of the <code>reservation</code> property is <code>reservation=<em>size</em></code>, so to set a reservation of 10 GB on <span class="filename">storage/home/bob</span>, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set reservation=10G storage/home/bob</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To clear any reservation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set reservation=none storage/home/bob</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The same principle applies to the <code>refreservation</code> property for setting a <a href="#zfs-term-refreservation">Reference Reservation</a>, with the general format <code>refreservation=<em>size</em></code>.</p>
</div>
<div class="paragraph">
<p>This command shows any reservations or refreservations that exist on <span class="filename">storage/home/bob</span>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get reservation storage/home/bob</span>
<span class="c"># zfs get refreservation storage/home/bob</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-compression">22.4.10. Compression<a class="anchor" href="#zfs-zfs-compression"></a></h3>
<div class="paragraph">
<p>ZFS provides transparent compression. Compressing data written at the block level saves space and also increases disk throughput. If data compresses by 25% the compressed data writes to the disk at the same rate as the uncompressed version, resulting in an effective write speed of 125%. Compression can also be a great alternative to <a href="#zfs-zfs-deduplication">Deduplication</a> because it does not require extra memory.</p>
</div>
<div class="paragraph">
<p>ZFS offers different compression algorithms, each with different trade-offs. The introduction of LZ4 compression in ZFS v5000 enables compressing the entire pool without the large performance trade-off of other algorithms. The biggest advantage to LZ4 is the <em>early abort</em> feature. If LZ4 does not achieve at least 12.5% compression in the header part of the data, ZFS writes the block uncompressed to avoid wasting CPU cycles trying to compress data that is either already compressed or uncompressible. For details about the different compression algorithms available in ZFS, see the <a href="#zfs-term-compression">Compression</a> entry in the terminology section.</p>
</div>
<div class="paragraph">
<p>The administrator can see the effectiveness of compression using dataset properties.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs get used,compressratio,compression,logicalused mypool/compressed_dataset</span>
NAME        PROPERTY          VALUE     SOURCE
mypool/compressed_dataset  used              449G      -
mypool/compressed_dataset  compressratio     1.11x     -
mypool/compressed_dataset  compression       lz4       <span class="nb">local
</span>mypool/compressed_dataset  logicalused       496G      -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The dataset is using 449 GB of space (the used property). Without compression, it would have taken 496 GB of space (the <code>logicalused</code> property). This results in a 1.11:1 compression ratio.</p>
</div>
<div class="paragraph">
<p>Compression can have an unexpected side effect when combined with <a href="#zfs-term-userquota">User Quotas</a>. User quotas restrict how much actual space a user consumes on a dataset <em>after compression</em>. If a user has a quota of 10 GB, and writes 10 GB of compressible data, they will still be able to store more data. If they later update a file, say a database, with more or less compressible data, the amount of space available to them will change. This can result in the odd situation where a user did not increase the actual amount of data (the <code>logicalused</code> property), but the change in compression caused them to reach their quota limit.</p>
</div>
<div class="paragraph">
<p>Compression can have a similar unexpected interaction with backups. Quotas are often used to limit data storage to ensure there is enough backup space available. Since quotas do not consider compression ZFS may write more data than would fit with uncompressed backups.</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-compression-zstd">22.4.11. Zstandard Compression<a class="anchor" href="#zfs-zfs-compression-zstd"></a></h3>
<div class="paragraph">
<p>OpenZFS 2.0 added a new compression algorithm. Zstandard (Zstd) offers higher compression ratios than the default LZ4 while offering much greater speeds than the alternative, gzip. OpenZFS 2.0 is available starting with FreeBSD 12.1-RELEASE via <a class="package" href="https://cgit.freebsd.org/ports/tree/sysutils/openzfs/">sysutils/openzfs</a> and has been the default in since FreeBSD 13.0-RELEASE.</p>
</div>
<div class="paragraph">
<p>Zstd provides a large selection of compression levels, providing fine-grained control over performance versus compression ratio. One of the main advantages of Zstd is that the decompression speed is independent of the compression level. For data written once but read often, Zstd allows the use of the highest compression levels without a read performance penalty.</p>
</div>
<div class="paragraph">
<p>Even with frequent data updates, enabling compression often provides higher performance. One of the biggest advantages comes from the compressed ARC feature. ZFS’s Adaptive Replacement Cache (ARC) caches the compressed version of the data in RAM, decompressing it each time. This allows the same amount of RAM to store more data and metadata, increasing the cache hit ratio.</p>
</div>
<div class="paragraph">
<p>ZFS offers 19 levels of Zstd compression, each offering incrementally more space savings in exchange for slower compression. The default level is <code>zstd-3</code> and offers greater compression than LZ4 without being much slower. Levels above 10 require large amounts of memory to compress each block and systems with less than 16 GB of RAM should not use them. ZFS uses a selection of the Zstd_fast_ levels also, which get correspondingly faster but supports lower compression ratios. ZFS supports <code>zstd-fast-1</code> through <code>zstd-fast-10</code>, <code>zstd-fast-20</code> through <code>zstd-fast-100</code> in increments of 10, and <code>zstd-fast-500</code> and <code>zstd-fast-1000</code> which provide minimal compression, but offer high performance.</p>
</div>
<div class="paragraph">
<p>If ZFS is not able to get the required memory to compress a block with Zstd, it will fall back to storing the block uncompressed. This is unlikely to happen except at the highest levels of Zstd on memory constrained systems. ZFS counts how often this has occurred since loading the ZFS module with <code>kstat.zfs.misc.zstd.compress_alloc_fail</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-deduplication">22.4.12. Deduplication<a class="anchor" href="#zfs-zfs-deduplication"></a></h3>
<div class="paragraph">
<p>When enabled, <a href="#zfs-term-deduplication">deduplication</a> uses the checksum of each block to detect duplicate blocks. When a new block is a duplicate of an existing block, ZFS writes a new reference to the existing data instead of the whole duplicate block. Tremendous space savings are possible if the data contains a lot of duplicated files or repeated information. Warning: deduplication requires a large amount of memory, and enabling compression instead provides most of the space savings without the extra cost.</p>
</div>
<div class="paragraph">
<p>To activate deduplication, set the <code>dedup</code> property on the target pool:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zfs set dedup=on pool</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Deduplicating only affects new data written to the pool. Merely activating this option will not deduplicate data already written to the pool. A pool with a freshly activated deduplication property will look like this example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool list</span>
NAME  SIZE ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG   CAP   DEDUP   HEALTH   ALTROOT
pool 2.84G 2.19M 2.83G         -         -     0%    0%   1.00x   ONLINE   -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>DEDUP</code> column shows the actual rate of deduplication for the pool. A value of <code>1.00x</code> shows that data has not deduplicated yet. The next example copies some system binaries three times into different directories on the deduplicated pool created above.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># for d in dir1 dir2 dir3; do</span>
<span class="gp">&gt; </span>mkdir <span class="nv">$d</span> <span class="o">&amp;&amp;</span> cp -R /usr/bin <span class="nv">$d</span> &amp;
<span class="gp">&gt; </span><span class="k">done</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>To observe deduplicating of redundant data, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zpool list</span>
NAME SIZE  ALLOC  FREE   CKPOINT  EXPANDSZ   FRAG  CAP   DEDUP   HEALTH   ALTROOT
pool 2.84G 20.9M 2.82G         -         -     0%   0%   3.00x   ONLINE   -</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>DEDUP</code> column shows a factor of <code>3.00x</code>. Detecting and deduplicating copies of the data uses a third of the space. The potential for space savings can be enormous, but comes at the cost of having enough memory to keep track of the deduplicated blocks.</p>
</div>
<div class="paragraph">
<p>Deduplication is not always beneficial when the data in a pool is not redundant. ZFS can show potential space savings by simulating deduplication on an existing pool:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># zdb -S pool</span>
Simulated DDT histogram:

bucket              allocated                       referenced
______   ______________________________   ______________________________
refcnt   blocks   LSIZE   PSIZE   DSIZE   blocks   LSIZE   PSIZE   DSIZE
------   ------   -----   -----   -----   ------   -----   -----   -----
     1    2.58M    289G    264G    264G    2.58M    289G    264G    264G
     2     206K   12.6G   10.4G   10.4G     430K   26.4G   21.6G   21.6G
     4    37.6K    692M    276M    276M     170K   3.04G   1.26G   1.26G
     8    2.18K   45.2M   19.4M   19.4M    20.0K    425M    176M    176M
    16      174   2.83M   1.20M   1.20M    3.33K   48.4M   20.4M   20.4M
    32       40   2.17M    222K    222K    1.70K   97.2M   9.91M   9.91M
    64        9     56K   10.5K   10.5K      865   4.96M    948K    948K
   128        2   9.50K      2K      2K      419   2.11M    438K    438K
   256        5   61.5K     12K     12K    1.90K   23.0M   4.47M   4.47M
    1K        2      1K      1K      1K    2.98K   1.49M   1.49M   1.49M
 Total    2.82M    303G    275G    275G    3.20M    319G    287G    287G

dedup <span class="o">=</span> 1.05, compress <span class="o">=</span> 1.11, copies <span class="o">=</span> 1.00, dedup <span class="k">*</span> compress / copies <span class="o">=</span> 1.16</code></pre>
</div>
</div>
<div class="paragraph">
<p>After <code>zdb -S</code> finishes analyzing the pool, it shows the space reduction ratio that activating deduplication would achieve. In this case, <code>1.16</code> is a poor space saving ratio mainly provided by compression. Activating deduplication on this pool would not save any amount of space, and is not worth the amount of memory required to enable deduplication. Using the formula <em>ratio = dedup * compress / copies</em>, system administrators can plan the storage allocation, deciding whether the workload will contain enough duplicate blocks to justify the memory requirements. If the data is reasonably compressible, the space savings may be good. Good practice is to enable compression first as compression also provides greatly increased performance. Enable deduplication in cases where savings are considerable and with enough available memory for the <a href="#zfs-term-deduplication">DDT</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-jail">22.4.13. ZFS and Jails<a class="anchor" href="#zfs-zfs-jail"></a></h3>
<div class="paragraph">
<p>Use <code>zfs jail</code> and the corresponding <code>jailed</code> property to delegate a ZFS dataset to a <a href="../jails/#jails">Jail</a>. <code>zfs jail <em>jailid</em></code> attaches a dataset to the specified jail, and <code>zfs unjail</code> detaches it. To control the dataset from within a jail, set the <code>jailed</code> property. ZFS forbids mounting a jailed dataset on the host because it may have mount points that would compromise the security of the host.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-zfs-allow">22.5. Delegated Administration<a class="anchor" href="#zfs-zfs-allow"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>A comprehensive permission delegation system allows unprivileged users to perform ZFS administration functions. For example, if each user’s home directory is a dataset, users need permission to create and destroy snapshots of their home directories. A user performing backups can get permission to use replication features. ZFS allows a usage statistics script to run with access to only the space usage data for all users. Delegating the ability to delegate permissions is also possible. Permission delegation is possible for each subcommand and most properties.</p>
</div>
<div class="sect2">
<h3 id="zfs-zfs-allow-create">22.5.1. Delegating Dataset Creation<a class="anchor" href="#zfs-zfs-allow-create"></a></h3>
<div class="paragraph">
<p><code>zfs allow <em>someuser</em> create <em>mydataset</em></code> gives the specified user permission to create child datasets under the selected parent dataset. A caveat: creating a new dataset involves mounting it. That requires setting the FreeBSD <code>vfs.usermount</code> <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a> to <code>1</code> to allow non-root users to mount a file system. Another restriction aimed at preventing abuse: non-<code>root</code> users must own the mountpoint where mounting the file system.</p>
</div>
</div>
<div class="sect2">
<h3 id="zfs-zfs-allow-allow">22.5.2. Delegating Permission Delegation<a class="anchor" href="#zfs-zfs-allow-allow"></a></h3>
<div class="paragraph">
<p><code>zfs allow <em>someuser</em> allow <em>mydataset</em></code> gives the specified user the ability to assign any permission they have on the target dataset, or its children, to other users. If a user has the <code>snapshot</code> permission and the <code>allow</code> permission, that user can then grant the <code>snapshot</code> permission to other users.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-advanced">22.6. Advanced Topics<a class="anchor" href="#zfs-advanced"></a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="zfs-advanced-tuning">22.6.1. Tuning<a class="anchor" href="#zfs-advanced-tuning"></a></h3>
<div class="paragraph">
<p>Adjust tunables to make ZFS perform best for different workloads.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="zfs-advanced-tuning-arc_max"></a> <code><em>vfs.zfs.arc.max</em></code> starting with 13.x (<code>vfs.zfs.arc_max</code> for 12.x) - Upper size of the <a href="#zfs-term-arc">ARC</a>. The default is all RAM but 1 GB, or 5/8 of all RAM, whichever is more. Use a lower value if the system runs any other daemons or processes that may require memory. Adjust this value at runtime with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a> and set it in <span class="filename">/boot/loader.conf</span> or <span class="filename">/etc/sysctl.conf</span>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-arc_meta_limit"></a> <code><em>vfs.zfs.arc.meta_limit</em></code> starting with 13.x (<code>vfs.zfs.arc_meta_limit</code> for 12.x)` - Limit the amount of the <a href="#zfs-term-arc">ARC</a> used to store metadata. The default is one fourth of <code>vfs.zfs.arc.max</code>. Increasing this value will improve performance if the workload involves operations on a large number of files and directories, or frequent metadata operations, at the cost of less file data fitting in the <a href="#zfs-term-arc">ARC</a>. Adjust this value at runtime with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a> in <span class="filename">/boot/loader.conf</span> or <span class="filename">/etc/sysctl.conf</span>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-arc_min"></a> <code><em>vfs.zfs.arc.min</em></code> starting with 13.x (<code>vfs.zfs.arc_min</code> for 12.x) - Lower size of the <a href="#zfs-term-arc">ARC</a>. The default is one half of <code>vfs.zfs.arc.meta_limit</code>. Adjust this value to prevent other applications from pressuring out the entire <a href="#zfs-term-arc">ARC</a>. Adjust this value at runtime with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a> and in <span class="filename">/boot/loader.conf</span> or <span class="filename">/etc/sysctl.conf</span>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-vdev-cache-size"></a> <code><em>vfs.zfs.vdev.cache.size</em></code> - A preallocated amount of memory reserved as a cache for each device in the pool. The total amount of memory used will be this value multiplied by the number of devices. Set this value at boot time and in <span class="filename">/boot/loader.conf</span>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-min-auto-ashift"></a> <code><em>vfs.zfs.min_auto_ashift</em></code> - Lower <code>ashift</code> (sector size) used automatically at pool creation time. The value is a power of two. The default value of <code>9</code> represents <code>2^9 = 512</code>, a sector size of 512 bytes. To avoid <em>write amplification</em> and get the best performance, set this value to the largest sector size used by a device in the pool.</p>
<div class="paragraph">
<p>Common drives have 4 KB sectors. Using the default <code>ashift</code> of <code>9</code> with these drives results in write amplification on these devices. Data contained in a single 4 KB write is instead written in eight 512-byte writes. ZFS tries to read the native sector size from all devices when creating a pool, but drives with 4 KB sectors report that their sectors are 512 bytes for compatibility. Setting <code>vfs.zfs.min_auto_ashift</code> to <code>12</code> (<code>2^12 = 4096</code>) before creating a pool forces ZFS to use 4 KB blocks for best performance on these drives.</p>
</div>
<div class="paragraph">
<p>Forcing 4 KB blocks is also useful on pools with planned disk upgrades. Future disks use 4 KB sectors, and <code>ashift</code> values cannot change after creating a pool.</p>
</div>
<div class="paragraph">
<p>In some specific cases, the smaller 512-byte block size might be preferable. When used with 512-byte disks for databases or as storage for virtual machines, less data transfers during small random reads. This can provide better performance when using a smaller ZFS record size.</p>
</div>
</li>
<li>
<p><a id="zfs-advanced-tuning-prefetch_disable"></a> <code><em>vfs.zfs.prefetch_disable</em></code> - Disable prefetch. A value of <code>0</code> enables and <code>1</code> disables it. The default is <code>0</code>, unless the system has less than 4 GB of RAM. Prefetch works by reading larger blocks than requested into the <a href="#zfs-term-arc">ARC</a> in hopes to soon need the data. If the workload has a large number of random reads, disabling prefetch may actually improve performance by reducing unnecessary reads. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-vdev-trim_on_init"></a> <code><em>vfs.zfs.vdev.trim_on_init</em></code> - Control whether new devices added to the pool have the <code>TRIM</code> command run on them. This ensures the best performance and longevity for SSDs, but takes extra time. If the device has already been secure erased, disabling this setting will make the addition of the new device faster. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-vdev-max_pending"></a> <code><em>vfs.zfs.vdev.max_pending</em></code> - Limit the number of pending I/O requests per device. A higher value will keep the device command queue full and may give higher throughput. A lower value will reduce latency. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-top_maxinflight"></a> <code><em>vfs.zfs.top_maxinflight</em></code> - Upper number of outstanding I/Os per top-level <a href="#zfs-term-vdev">vdev</a>. Limits the depth of the command queue to prevent high latency. The limit is per top-level vdev, meaning the limit applies to each <a href="#zfs-term-vdev-mirror">mirror</a>, <a href="#zfs-term-vdev-raidz">RAID-Z</a>, or other vdev independently. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-l2arc_write_max"></a> <code><em>vfs.zfs.l2arc_write_max</em></code> - Limit the amount of data written to the <a href="#zfs-term-l2arc">L2ARC</a> per second. This tunable extends the longevity of SSDs by limiting the amount of data written to the device. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-l2arc_write_boost"></a> <code><em>vfs.zfs.l2arc_write_boost</em></code> - Adds the value of this tunable to <a href="#zfs-advanced-tuning-l2arc_write_max"><code>vfs.zfs.l2arc_write_max</code></a> and increases the write speed to the SSD until evicting the first block from the <a href="#zfs-term-l2arc">L2ARC</a>. This &#34;Turbo Warmup Phase&#34; reduces the performance loss from an empty <a href="#zfs-term-l2arc">L2ARC</a> after a reboot. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-scrub_delay"></a><code><em>vfs.zfs.scrub_delay</em></code> - Number of ticks to delay between each I/O during a <a href="#zfs-term-scrub"><code>scrub</code></a>. To ensure that a <code>scrub</code> does not interfere with the normal operation of the pool, if any other I/O is happening the <code>scrub</code> will delay between each command. This value controls the limit on the total IOPS (I/Os Per Second) generated by the <code>scrub</code>. The granularity of the setting is determined by the value of <code>kern.hz</code> which defaults to 1000 ticks per second. Changing this setting results in a different effective IOPS limit. The default value is <code>4</code>, resulting in a limit of: 1000 ticks/sec / 4 = 250 IOPS. Using a value of <em>20</em> would give a limit of: 1000 ticks/sec / 20 = 50 IOPS. Recent activity on the pool limits the speed of <code>scrub</code>, as determined by <a href="#zfs-advanced-tuning-scan_idle"><code>vfs.zfs.scan_idle</code></a>. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-resilver_delay"></a> <code><em>vfs.zfs.resilver_delay</em></code> - Number of milliseconds of delay inserted between each I/O during a <a href="#zfs-term-resilver">resilver</a>. To ensure that a resilver does not interfere with the normal operation of the pool, if any other I/O is happening the resilver will delay between each command. This value controls the limit of total IOPS (I/Os Per Second) generated by the resilver. ZFS determins the granularity of the setting by the value of <code>kern.hz</code> which defaults to 1000 ticks per second. Changing this setting results in a different effective IOPS limit. The default value is 2, resulting in a limit of: 1000 ticks/sec / 2 = 500 IOPS. Returning the pool to an <a href="#zfs-term-online">Online</a> state may be more important if another device failing could <a href="#zfs-term-faulted">Fault</a> the pool, causing data loss. A value of 0 will give the resilver operation the same priority as other operations, speeding the healing process. Other recent activity on the pool limits the speed of resilver, as determined by <a href="#zfs-advanced-tuning-scan_idle"><code>vfs.zfs.scan_idle</code></a>. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-scan_idle"></a> <code><em>vfs.zfs.scan_idle</em></code> - Number of milliseconds since the last operation before considering the pool is idle. ZFS disables the rate limiting for <a href="#zfs-term-scrub"><code>scrub</code></a> and <a href="#zfs-term-resilver">resilver</a> when the pool is idle. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
<li>
<p><a id="zfs-advanced-tuning-txg-timeout"></a> <code><em>vfs.zfs.txg.timeout</em></code> - Upper number of seconds between <a href="#zfs-term-txg">transaction group</a>s. The current transaction group writes to the pool and a fresh transaction group starts if this amount of time elapsed since the previous transaction group. A transaction group may trigger earlier if writing enough data. The default value is 5 seconds. A larger value may improve read performance by delaying asynchronous writes, but this may cause uneven performance when writing the transaction group. Adjust this value at any time with <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="zfs-advanced-i386">22.6.2. ZFS on i386<a class="anchor" href="#zfs-advanced-i386"></a></h3>
<div class="paragraph">
<p>Some of the features provided by ZFS are memory intensive, and may require tuning for upper efficiency on systems with limited RAM.</p>
</div>
<div class="sect3">
<h4 id="_memory">22.6.2.1. Memory<a class="anchor" href="#_memory"></a></h4>
<div class="paragraph">
<p>As a lower value, the total system memory should be at least one gigabyte. The amount of recommended RAM depends upon the size of the pool and which features ZFS uses. A general rule of thumb is 1 GB of RAM for every 1 TB of storage. If using the deduplication feature, a general rule of thumb is 5 GB of RAM per TB of storage to deduplicate. While some users use ZFS with less RAM, systems under heavy load may panic due to memory exhaustion. ZFS may require further tuning for systems with less than the recommended RAM requirements.</p>
</div>
</div>
<div class="sect3">
<h4 id="_kernel_configuration">22.6.2.2. Kernel Configuration<a class="anchor" href="#_kernel_configuration"></a></h4>
<div class="paragraph">
<p>Due to the address space limitations of the i386™ platform, ZFS users on the i386™ architecture must add this option to a custom kernel configuration file, rebuild the kernel, and reboot:</p>
</div>
<div class="literalblock programlisting">
<div class="content">
<pre>options        KVA_PAGES=512</pre>
</div>
</div>
<div class="paragraph">
<p>This expands the kernel address space, allowing the <code>vm.kvm_size</code> tunable to push beyond the imposed limit of 1 GB, or the limit of 2 GB for PAE. To find the most suitable value for this option, divide the desired address space in megabytes by four. In this example <code>512</code> for 2 GB.</p>
</div>
</div>
<div class="sect3">
<h4 id="_loader_tunables">22.6.2.3. Loader Tunables<a class="anchor" href="#_loader_tunables"></a></h4>
<div class="paragraph">
<p>Increases the <span class="filename">kmem</span> address space on all FreeBSD architectures. A test system with 1 GB of physical memory benefitted from adding these options to <span class="filename">/boot/loader.conf</span> and then restarting:</p>
</div>
<div class="literalblock programlisting">
<div class="content">
<pre>vm.kmem_size=&#34;330M&#34;
vm.kmem_size_max=&#34;330M&#34;
vfs.zfs.arc.max=&#34;40M&#34;
vfs.zfs.vdev.cache.size=&#34;5M&#34;</pre>
</div>
</div>
<div class="paragraph">
<p>For a more detailed list of recommendations for ZFS-related tuning, see <a href="https://wiki.freebsd.org/ZFSTuningGuide" class="bare">https://wiki.freebsd.org/ZFSTuningGuide</a>.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-links">22.7. Further Resources<a class="anchor" href="#zfs-links"></a></h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="https://openzfs.org/">OpenZFS</a></p>
</li>
<li>
<p><a href="https://wiki.freebsd.org/ZFSTuningGuide">FreeBSD Wiki - ZFS Tuning</a></p>
</li>
<li>
<p><a href="https://calomel.org/zfs_raid_speed_capacity.html">Calomel Blog - ZFS Raidz Performance, Capacity and Integrity</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zfs-term">22.8. ZFS Features and Terminology<a class="anchor" href="#zfs-term"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>More than a file system, ZFS is fundamentally different. ZFS combines the roles of file system and volume manager, enabling new storage devices to add to a live system and having the new space available on the existing file systems in that pool at once. By combining the traditionally separate roles, ZFS is able to overcome previous limitations that prevented RAID groups being able to grow. A <em>vdev</em> is a top level device in a pool and can be a simple disk or a RAID transformation such as a mirror or RAID-Z array. ZFS file systems (called <em>datasets</em>) each have access to the combined free space of the entire pool. Used blocks from the pool decrease the space available to each file system. This approach avoids the common pitfall with extensive partitioning where free space becomes fragmented across the partitions.</p>
</div>
<table class="tableblock frame-all grid-all stretch informaltable">
<colgroup>
<col style="width: 10%;"/>
<col style="width: 90%;"/>
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-pool"></a>pool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A storage <em>pool</em> is the most basic building block of ZFS. A pool consists of one or more vdevs, the underlying devices that store the data. A pool is then used to create one or more file systems (datasets) or block devices (volumes).
These datasets and volumes share the pool of remaining free space. Each pool is uniquely identified by a name and a GUID. The ZFS version number on the pool determines the features available.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-vdev"></a>vdev Types</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>A pool consists of one or more vdevs, which themselves are a single disk or a group of disks, transformed to a RAID. When using a lot of vdevs, ZFS spreads data across the vdevs to increase performance and maximize usable space. All vdevs must be at least 128 MB in size.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="zfs-term-vdev-disk"></a> <em>Disk</em> - The most basic vdev type is a standard block device. This can be an entire disk (such as <span class="filename">/dev/ada0</span> or <span class="filename">/dev/da0</span>) or a partition (<span class="filename">/dev/ada0p3</span>). On FreeBSD, there is no performance penalty for using a partition rather than the entire disk. This differs from recommendations made by the Solaris documentation.</p>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Using an entire disk as part of a bootable pool is strongly discouraged, as this may render the pool unbootable.
Likewise, you should not use an entire disk as part of a mirror or RAID-Z vdev.
Reliably determining the size of an unpartitioned disk at boot time is impossible and there’s no place to put in boot code.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p><a id="zfs-term-vdev-file"></a> <em>File</em> - Regular files may make up ZFS pools, which is useful for testing and experimentation. Use the full path to the file as the device path in <code>zpool create</code>.</p>
</li>
<li>
<p><a id="zfs-term-vdev-mirror"></a> <em>Mirror</em> - When creating a mirror, specify the <code>mirror</code> keyword followed by the list of member devices for the mirror. A mirror consists of two or more devices, writing all data to all member devices. A mirror vdev will hold as much data as its smallest member. A mirror vdev can withstand the failure of all but one of its members without losing any data.</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>To upgrade a regular single disk vdev to a mirror vdev at any time, use <code>zpool <a href="#zfs-zpool-attach">attach</a></code>.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p><a id="zfs-term-vdev-raidz"></a> <em>RAID-Z</em> - ZFS uses RAID-Z, a variation on standard RAID-5 that offers better distribution of parity and eliminates the &#34;RAID-5 write hole&#34; in which the data and parity information become inconsistent after an unexpected restart. ZFS supports three levels of RAID-Z which provide varying levels of redundancy in exchange for decreasing levels of usable storage. ZFS uses RAID-Z1 through RAID-Z3 based on the number of parity devices in the array and the number of disks which can fail before the pool stops  being operational.</p>
<div class="paragraph">
<p>In a RAID-Z1 configuration with four disks, each 1 TB, usable storage is 3 TB and the pool will still be able to operate in degraded mode with one faulted disk. If another disk goes offline before replacing and resilvering the faulted disk would result in losing all pool data.</p>
</div>
<div class="paragraph">
<p>In a RAID-Z3 configuration with eight disks of 1 TB, the volume will provide 5 TB of usable space and still be able to operate with three faulted disks. Sun™ recommends no more than nine disks in a single vdev. If more disks make up the configuration, the recommendation is to divide them into separate vdevs and stripe the pool data across them.</p>
</div>
<div class="paragraph">
<p>A configuration of two RAID-Z2 vdevs consisting of 8 disks each would create something like a RAID-60 array. A RAID-Z group’s storage capacity is about the size of the smallest disk multiplied by the number of non-parity disks. Four 1 TB disks in RAID-Z1 has an effective size of about 3 TB, and an array of eight 1 TB disks in RAID-Z3 will yield 5 TB of usable space.</p>
</div>
</li>
<li>
<p><a id="zfs-term-vdev-spare"></a> <em>Spare</em> - ZFS has a special pseudo-vdev type for keeping track of available hot spares. Note that installed hot spares are not deployed automatically; manually configure them to replace the failed device using <code>zfs replace</code>.</p>
</li>
<li>
<p><a id="zfs-term-vdev-log"></a> <em>Log</em> - ZFS Log Devices, also known as ZFS Intent Log (<a href="#zfs-term-zil">ZIL</a>) move the intent log from the regular pool devices to a dedicated device, typically an SSD. Having a dedicated log device improves the performance of applications with a high volume of synchronous writes like databases. Mirroring of log devices is possible, but RAID-Z is not supported. If using a lot of log devices, writes will be load-balanced across them.</p>
</li>
<li>
<p><a id="zfs-term-vdev-cache"></a> <em>Cache</em> - Adding a cache vdev to a pool will add the storage of the cache to the <a href="#zfs-term-l2arc">L2ARC</a>. Mirroring cache devices is impossible. Since a cache device stores only new copies of existing data, there is no risk of data loss.</p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-txg"></a> Transaction Group (TXG)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Transaction Groups are the way ZFS groups blocks changes together and writes them to the pool. Transaction groups are the atomic unit that ZFS uses to ensure consistency. ZFS assigns each transaction group a unique 64-bit consecutive identifier. There can be up to three active transaction groups at a time, one in each of these three states:</p>
<p class="tableblock">* <em>Open</em> - A new transaction group begins in the open state and accepts new writes. There is always a transaction group in the open state, but the transaction group may refuse new writes if it has reached a limit. Once the open transaction group has reached a limit, or reaching the <a href="#zfs-advanced-tuning-txg-timeout"><code>vfs.zfs.txg.timeout</code></a>, the transaction group advances to the next state.
* <em>Quiescing</em> - A short state that allows any pending operations to finish without blocking the creation of a new open transaction group. Once all the transactions in the group have completed, the transaction group advances to the final state.
* <em>Syncing</em> - Write all the data in the transaction group to stable storage. This process will in turn change other data, such as metadata and space maps, that ZFS will also write to stable storage. The process of syncing involves several passes. On the first and biggest, all the changed data blocks; next come the metadata, which may take several passes to complete. Since allocating space for the data blocks generates new metadata, the syncing state cannot finish until a pass completes that does not use any new space. The syncing state is also where <em>synctasks</em> complete. Synctasks are administrative operations such as creating or destroying snapshots and datasets that complete the uberblock change. Once the sync state completes the transaction group in the quiescing state advances to the syncing state. All administrative functions, such as <a href="#zfs-term-snapshot"><code>snapshot</code></a> write as part of the transaction group. ZFS adds a created synctask to the open transaction group, and that group advances as fast as possible to the syncing state to reduce the latency of administrative commands.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-arc"></a>Adaptive Replacement Cache (ARC)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ZFS uses an Adaptive Replacement Cache (ARC), rather than a more traditional Least Recently Used (LRU) cache. An LRU cache is a simple list of items in the cache, sorted by how recently object was used, adding new items to the head of the list. When the cache is full, evicting items from the tail of the list makes room for more active objects. An ARC consists of four lists; the Most Recently Used (MRU) and Most Frequently Used (MFU) objects, plus a ghost list for each. These ghost lists track evicted objects to prevent adding them back to the cache. This increases the cache hit ratio by avoiding objects that have a history of occasional use. Another advantage of using both an MRU and MFU is that scanning an entire file system would evict all data from an MRU or LRU cache in favor of this freshly accessed content. With ZFS, there is also an MFU that tracks the most frequently used objects, and the cache of the most commonly accessed blocks remains.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-l2arc"></a>L2ARC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">L2ARC is the second level of the ZFS caching system. RAM stores the primary ARC. Since the amount of available RAM is often limited, ZFS can also use <a href="#zfs-term-vdev-cache">cache vdevs</a>. Solid State Disks (SSDs) are often used as these cache devices due to their higher speed and lower latency compared to traditional spinning disks. L2ARC is entirely optional, but having one will increase read speeds for cached files on the SSD instead of having to read from the regular disks. L2ARC can also speed up <a href="#zfs-term-deduplication">deduplication</a> because a deduplication table (DDT) that does not fit in RAM but does fit in the L2ARC will be much faster than a DDT that must read from disk. Limits on the data rate added to the cache devices prevents prematurely wearing out SSDs with extra writes. Until the cache is full (the first block evicted to make room), writes to the L2ARC limit to the sum of the write limit and the boost limit, and afterwards limit to the write limit. A pair of <a href="https://man.freebsd.org/cgi/man.cgi?query=sysctl&amp;sektion=8&amp;format=html">sysctl(8)</a> values control these rate limits. <a href="#zfs-advanced-tuning-l2arc_write_max"><code>vfs.zfs.l2arc_write_max</code></a> controls the number of bytes written to the cache per second, while <a href="#zfs-advanced-tuning-l2arc_write_boost"><code>vfs.zfs.l2arc_write_boost</code></a> adds to this limit during the &#34;Turbo Warmup Phase&#34; (Write Boost).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-zil"></a>ZIL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ZIL accelerates synchronous transactions by using storage devices like SSDs that are faster than those used in the main storage pool. When an application requests a synchronous write (a guarantee that the data is stored to disk rather than merely cached for later writes), writing the data to the faster ZIL storage then later flushing it out to the regular disks greatly reduces latency and improves performance. Synchronous workloads like databases will profit from a ZIL alone. Regular asynchronous writes such as copying files will not use the ZIL at all.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-cow"></a>Copy-On-Write</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unlike a traditional file system, ZFS writes a different block rather than overwriting the old data in place. When completing this write the metadata updates to point to the new location. When a shorn write (a system crash or power loss in the middle of writing a file) occurs, the entire original contents of the file are still available and ZFS discards the incomplete write. This also means that ZFS does not require a <a href="https://man.freebsd.org/cgi/man.cgi?query=fsck&amp;sektion=8&amp;format=html">fsck(8)</a> after an unexpected shutdown.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-dataset"></a>Dataset</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>Dataset</em> is the generic term for a ZFS file system, volume, snapshot or clone. Each dataset has a unique name in the format <em>poolname/path@snapshot</em>. The root of the pool is a dataset as well. Child datasets have hierarchical names like directories. For example, <em>mypool/home</em>, the home dataset, is a child of <em>mypool</em> and inherits properties from it. Expand this further by creating <em>mypool/home/user</em>. This grandchild dataset will inherit properties from the parent and grandparent. Set properties on a child to override the defaults inherited from the parent and grandparent. Administration of datasets and their children can be <a href="#zfs-zfs-allow">delegated</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-filesystem"></a>File system</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A ZFS dataset is most often used as a file system. Like most other file systems, a ZFS file system mounts somewhere in the systems directory hierarchy and contains files and directories of its own with permissions, flags, and other metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-volume"></a>Volume</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ZFS can also create volumes, which appear as disk devices. Volumes have a lot of the same features as datasets, including copy-on-write, snapshots, clones, and checksumming. Volumes can be useful for running other file system formats on top of ZFS, such as UFS virtualization, or exporting iSCSI extents.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-snapshot"></a>Snapshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <a href="#zfs-term-cow">copy-on-write</a> (COW) design of ZFS allows for nearly instantaneous, consistent snapshots with arbitrary names. After taking a snapshot of a dataset, or a recursive snapshot of a parent dataset that will include all child datasets, new data goes to new blocks, but without reclaiming the old blocks as free space. The snapshot contains the original file system version and the live file system contains any changes made since taking the snapshot using no other space. New data written to the live file system uses new blocks to store this data. The snapshot will grow as the blocks are no longer used in the live file system, but in the snapshot alone. Mount these snapshots read-only allows recovering of previous file versions. A <a href="#zfs-zfs-snapshot">rollback</a> of a live file system to a specific snapshot is possible, undoing any changes that took place after taking the snapshot. Each block in the pool has a reference counter which keeps track of the snapshots, clones, datasets, or volumes use that block. As files and snapshots get deleted, the reference count  decreases, reclaiming the free space when no longer referencing a block. Marking snapshots with a <a href="#zfs-zfs-snapshot">hold</a> results in any attempt to destroy it will  returns an <code>EBUSY</code> error. Each snapshot can have holds with a unique name each. The <a href="#zfs-zfs-snapshot">release</a> command removes the hold so the snapshot can deleted. Snapshots, cloning, and rolling back works on volumes, but independently mounting does not.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-clone"></a>Clone</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cloning a snapshot is also possible. A clone is a writable version of a snapshot, allowing the file system to fork as a new dataset. As with a snapshot, a clone initially consumes no new space. As new data written to a clone uses new blocks, the size of the clone grows. When blocks are overwritten in the cloned file system or volume, the reference count on the previous block decreases. Removing the snapshot upon which a clone bases is impossible because the clone depends on it. The snapshot is the parent, and the clone is the child. Clones can be <em>promoted</em>, reversing this dependency and making the clone the parent and the previous parent the child. This operation requires no new space. Since the amount of space used by the parent and child reverses, it may affect existing quotas and reservations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-checksum"></a>Checksum</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Every block is also checksummed. The checksum algorithm used is a per-dataset property, see <a href="#zfs-zfs-set"><code>set</code></a>. The checksum of each block is transparently validated when read, allowing ZFS to detect silent corruption. If the data read does not match the expected checksum, ZFS will attempt to recover the data from any available redundancy, like mirrors or RAID-Z. Triggering a validation of all checksums with <a href="#zfs-term-scrub"><code>scrub</code></a>. Checksum algorithms include:</p>
<p class="tableblock">* <code>fletcher2</code>
* <code>fletcher4</code>
* <code>sha256</code>
 The <code>fletcher</code> algorithms are faster, but <code>sha256</code> is a strong cryptographic hash and has a much lower chance of collisions at the  cost of some performance. Deactivating checksums is possible, but  strongly discouraged.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-compression"></a>Compression</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Each dataset has a compression property, which defaults to off. Set this property to an available compression algorithm. This causes compression of all new data written to the dataset. Beyond a reduction in space used, read and write throughput often increases because fewer blocks need reading or writing.</p>
<p class="tableblock"><a id="zfs-term-compression-lz4"></a>
* <em>LZ4</em> - Added in ZFS pool version 5000 (feature flags), LZ4 is now the recommended compression algorithm. LZ4 works about 50% faster than LZJB when operating on compressible data, and is over three times faster when operating on uncompressible data. LZ4 also decompresses about 80% faster than LZJB. On modern CPUs, LZ4 can often compress at over 500 MB/s, and decompress at over 1.5 GB/s (per single CPU core).</p>
<p class="tableblock"><a id="zfs-term-compression-lzjb"></a>
* <em>LZJB</em> - The default compression algorithm. Created by Jeff Bonwick (one of the original creators of ZFS). LZJB offers good compression with less CPU overhead compared to GZIP. In the future, the default compression algorithm will change to LZ4.</p>
<p class="tableblock"><a id="zfs-term-compression-gzip"></a>
* <em>GZIP</em> - A popular stream compression algorithm available in ZFS. One of the main advantages of using GZIP is its configurable level of compression. When setting the <code>compress</code> property, the administrator can choose the level of compression, ranging from <code>gzip1</code>, the lowest level of compression, to <code>gzip9</code>, the highest level of compression. This gives the administrator control over how much CPU time to trade for saved disk space.</p>
<p class="tableblock"><a id="zfs-term-compression-zle"></a>
* <em>ZLE</em> - Zero Length Encoding is a special compression algorithm that compresses continuous runs of zeros alone. This compression algorithm is useful when the dataset contains large blocks of zeros.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-copies"></a>Copies</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When set to a value greater than 1, the <code>copies</code> property instructs ZFS to maintain copies of each block in the <a href="#zfs-term-filesystem">file system</a> or <a href="#zfs-term-volume">volume</a>. Setting this property on important datasets provides added redundancy from which to recover a block that does not match its checksum. In pools without redundancy, the copies feature is the single form of redundancy. The copies feature can recover from a single bad sector or other forms of minor corruption, but it does not protect the pool from the loss of an entire disk.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-deduplication"></a>Deduplication</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Checksums make it possible to detect duplicate blocks when writing data. With deduplication, the reference count of an existing, identical block increases, saving storage space. ZFS keeps a deduplication table (DDT) in memory to detect duplicate blocks. The table contains a list of unique checksums, the location of those blocks, and a reference count. When writing new data, ZFS calculates checksums and compares them to the list. When finding a match it uses the existing block. Using the SHA256 checksum algorithm with deduplication provides a secure cryptographic hash. Deduplication is tunable. If <code>dedup</code> is <code>on</code>, then a matching checksum means that the data is identical. Setting <code>dedup</code> to <code>verify</code>, ZFS performs a byte-for-byte check on the data ensuring they are actually identical. If the data is not identical, ZFS will note the hash collision and store the two blocks separately. As the DDT must store the hash of each unique block, it consumes a large amount of memory. A general rule of thumb is 5-6 GB of ram per 1 TB of deduplicated data). In situations not practical to have enough RAM to keep the entire DDT in memory, performance will suffer greatly as the DDT must read from disk before writing each new block. Deduplication can use L2ARC to store the DDT, providing a middle ground between fast system memory and slower disks. Consider using compression instead, which often provides nearly as much space savings without the increased memory.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-scrub"></a>Scrub</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Instead of a consistency check like <a href="https://man.freebsd.org/cgi/man.cgi?query=fsck&amp;sektion=8&amp;format=html">fsck(8)</a>, ZFS has <code>scrub</code>. <code>scrub</code> reads all data blocks stored on the pool and verifies their checksums against the known good checksums stored in the metadata. A periodic check of all the data stored on the pool ensures the recovery of any corrupted blocks before needing them. A scrub is not required after an unclean shutdown, but good practice is at least once every three months. ZFS verifies the checksum of each block during normal use, but a scrub makes certain to check even infrequently used blocks for silent corruption. ZFS improves data security in archival storage situations. Adjust the relative priority of <code>scrub</code> with <a href="#zfs-advanced-tuning-scrub_delay"><code>vfs.zfs.scrub_delay</code></a> to prevent the scrub from degrading the performance of other workloads on the pool.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-quota"></a>Dataset Quota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ZFS provides fast and accurate dataset, user, and group space accounting as well as quotas and space reservations. This gives the administrator fine grained control over space allocation and allows reserving space for critical file systems.</p>
<p class="tableblock">ZFS supports different types of quotas: the dataset quota, the <a href="#zfs-term-refquota">reference quota (refquota)</a>, the <a href="#zfs-term-userquota">user quota</a>, and the <a href="#zfs-term-groupquota">group quota</a>.</p>
<p class="tableblock">Quotas limit the total size of a dataset and its descendants, including snapshots of the dataset, child datasets, and the snapshots of those datasets.</p>
<p class="tableblock">[NOTE]
====
Volumes do not support quotas, as the <code>volsize</code> property acts as an implicit quota.
====</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-refquota"></a>Reference Quota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A reference quota limits the amount of space a dataset can consume by enforcing a hard limit. This hard limit includes space referenced by the dataset alone and does not include space used by descendants, such as file systems or snapshots.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-userquota"></a>User Quota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">User quotas are useful to limit the amount of space used by the specified user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-groupquota"></a>Group Quota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The group quota limits the amount of space that a specified group can consume.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-reservation"></a>Dataset Reservation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <code>reservation</code> property makes it possible to guarantee an amount of space for a specific dataset and its descendants. This means that setting a 10 GB reservation on <span class="filename">storage/home/bob</span> prevents other datasets from using up all free space, reserving at least 10 GB of space for this dataset. Unlike a regular <a href="#zfs-term-refreservation"><code>refreservation</code></a>, space used by snapshots and descendants is not counted against the reservation. For example, if taking a snapshot of <span class="filename">storage/home/bob</span>, enough disk space other than the <code>refreservation</code> amount must exist for the operation to succeed. Descendants of the main data set are not counted in the <code>refreservation</code> amount and so do not encroach on the space set.</p>
<p class="tableblock">Reservations of any sort are useful in situations such as planning and testing the suitability of disk space allocation in a new system, or ensuring that enough space is available on file systems for audio logs or system recovery procedures and files.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-refreservation"></a>Reference Reservation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <code>refreservation</code> property makes it possible to guarantee an amount of space for the use of a specific dataset <em>excluding</em> its descendants. This means that setting a 10 GB reservation on <span class="filename">storage/home/bob</span>, and another dataset tries to use the free space, reserving at least 10 GB of space  for this dataset. In contrast to a regular <a href="#zfs-term-reservation">reservation</a>, space used by snapshots and descendant datasets is not counted against the reservation. For example, if taking a snapshot of <span class="filename">storage/home/bob</span>, enough disk space other than the <code>refreservation</code> amount must exist for the operation to succeed. Descendants of the  main data set are not counted in the <code>refreservation</code> amount and so do not encroach on the space set.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-resilver"></a>Resilver</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When replacing a failed disk, ZFS must fill the new disk with the lost data. <em>Resilvering</em> is the process of using the parity information distributed across the remaining drives to calculate and write the missing data to the new drive.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-online"></a>Online</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A pool or vdev in the <code>Online</code> state has its member devices connected and fully operational. Individual devices in the <code>Online</code> state are functioning.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-offline"></a>Offline</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The administrator puts individual devices in an <code>Offline</code> state if enough redundancy exists to avoid putting the pool or vdev into a <a href="#zfs-term-faulted">Faulted</a> state. An administrator may choose to offline a disk in preparation for replacing it, or to make it easier to identify.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-degraded"></a>Degraded</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A pool or vdev in the <code>Degraded</code> state has one or more disks that disappeared or failed. The pool is still usable, but if other devices fail, the pool may become unrecoverable. Reconnecting the missing devices or replacing the failed disks will return the pool to an <a href="#zfs-term-online">Online</a> state after the reconnected or new device has completed the <a href="#zfs-term-resilver">Resilver</a> process.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="zfs-term-faulted"></a>Faulted</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A pool or vdev in the <code>Faulted</code> state is no longer operational. Accessing the data is no longer possible. A pool or vdev enters the <code>Faulted</code> state when the number of missing or failed devices exceeds the level of redundancy in the vdev. If reconnecting missing devices the pool will return to an <a href="#zfs-term-online">Online</a> state. Insufficient redundancy to compensate for the number of failed disks loses the pool contents and requires restoring from backups.</p></td>
</tr>
</tbody>
</table>
</div>
</div>

    </div>
    
    <hr />
    <div class="last-modified">
      <p><strong>Last modified on</strong>: January 3, 2024 by <a href="https://cgit.freebsd.org/doc/commit/?id=efa1c56" target="_blank">github actions</a></p>
    </div>
    
    <div class="buttons">
      
      <div class="prev">
        <i class="fa fa-angle-left" aria-hidden="true" title="Prev"></i>
        <div class="container">
          
            <a href=https://free.bsd-doc.org/zh-cn/books/handbook/geom class="direction">Prev</a>
          
        </div>
      </div>
      
      <div class="home">
        <i class="fa fa-home" aria-hidden="true" title="Home"></i>
        <div class="container">
          
            <a href="../" class="direction">Home</a>
          
        </div>
      </div>
      
      <div class="next">
        <div class="container">
          
            <a href=https://free.bsd-doc.org/zh-cn/books/handbook/filesystems  class="direction">Next</a>
          
        </div>
        <i class="fa fa-angle-right" aria-hidden="true" title="Next"></i>
      </div>
      
    </div>
    <label class="hidden book-menu-overlay" for="menu-control"></label>
  </div>
  <aside class="toc">
    <div class="toc-content">
      <h3>Table of Contents</h3>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#zfs-differences">22.1. ZFS 有何不同之处</a></li>
    <li><a href="#zfs-quickstart">22.2. 快速入门指南</a></li>
    <li><a href="#zfs-zpool">22.3. <code>zpool</code> 管理</a></li>
    <li><a href="#zfs-zfs">22.4. <code>zfs</code> 管理</a></li>
    <li><a href="#zfs-zfs-allow">22.5. Delegated Administration</a></li>
    <li><a href="#zfs-advanced">22.6. Advanced Topics</a></li>
    <li><a href="#zfs-links">22.7. Further Resources</a></li>
    <li><a href="#zfs-term">22.8. ZFS Features and Terminology</a></li>
  </ul>
</nav>
      <hr />
      
    </div>
  </aside>
  <a class="to-top" href="#top">
    <i class="fa fa-arrow-circle-up" aria-hidden="true"></i>
  </a>
</main>

    <footer>
  <div class="footer-container">
    <section class="logo-column">
          <img src="https://free.bsd-doc.org/images/FreeBSD-colors.svg" width="160" height="50" alt="FreeBSD logo" />
        <div class="options-container">
          
            <div class="language-container">
              <a id="languages" href="https://free.bsd-doc.org/zh-cn/languages">
                
                <img src="https://free.bsd-doc.org/images/language.png" class="language-image" alt="Choose language">
                <span>简体中文</span>
              </a>
            </div>
          
          <div class="theme-container">
            <select id="theme-chooser">
	      <option value="theme-system">System</option>
              <option value="theme-light">Light</option>
              <option value="theme-dark">Dark</option>
              <option value="theme-high-contrast">High contrast</option>
            </select>
          </div>
        </div>
      </section>
      
      <section class="copyright-column">
        <p>&copy; 1994-2024 The FreeBSD Project. All rights reserved</p>
        <span>Made with <span class="heart">♥</span> by the FreeBSD Community</span>
      </section>
  </div>
</footer>

  </body>
</html>
